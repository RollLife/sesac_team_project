"""
ìˆœì°¨ì²˜ë¦¬ ë²¤ì¹˜ë§ˆí¬ í”„ë¡œë“€ì„œ

Kafka ì—†ì´ ì§ì ‘ DBì— ì €ì¥í•˜ëŠ” ë°©ì‹ì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤.
ë„¤íŠ¸ì›Œí¬ ì§€ì—°ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ì—¬ ì‹¤ì œ ë¶„ì‚°í™˜ê²½ì—ì„œì˜ ì„±ëŠ¥ ì°¨ì´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
"""

import os
import sys
import time
import random
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from benchmark_common import BenchmarkResult, BenchmarkTimer, save_result, print_result_summary

from database import database, crud, models
from collect.order_generator import OrderGenerator
from collect.user_generator import UserGenerator
from collect.product_generator import ProductGenerator


# ë²¤ì¹˜ë§ˆí¬ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ë¡œ ì˜¤ë²„ë¼ì´ë“œ ê°€ëŠ¥)
TOTAL_RECORDS = int(os.environ.get('BENCHMARK_RECORDS', 5000))
SIMULATE_NETWORK_DELAY = os.environ.get('SIMULATE_NETWORK_DELAY', 'true').lower() == 'true'
NETWORK_DELAY_MS = int(os.environ.get('NETWORK_DELAY_MS', 20))  # 20ms ê¸°ë³¸ ì§€ì—°
BATCH_SIZE = int(os.environ.get('BATCH_SIZE', 100))


def simulate_network_delay():
    """ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì‹œë®¬ë ˆì´ì…˜ (ì›ê²© DB ì ‘ì† ì‹œë®¬ë ˆì´ì…˜)"""
    if SIMULATE_NETWORK_DELAY:
        # 20ms ê¸°ë³¸ + 0~10ms ëœë¤ ì§€í„°
        delay = (NETWORK_DELAY_MS + random.uniform(0, 10)) / 1000
        time.sleep(delay)


def run_sequential_benchmark():
    """ìˆœì°¨ì²˜ë¦¬ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           ìˆœì°¨ì²˜ë¦¬ ë²¤ì¹˜ë§ˆí¬ (Kafka ë¯¸ì‚¬ìš©)                    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  ë ˆì½”ë“œ ìˆ˜: {TOTAL_RECORDS:>10,}ê°œ                                    â•‘
â•‘  ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì‹œë®¬ë ˆì´ì…˜: {'ON' if SIMULATE_NETWORK_DELAY else 'OFF':<10}                    â•‘
â•‘  ì§€ì—° ì‹œê°„: {NETWORK_DELAY_MS:>10}ms                                   â•‘
â•‘  ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE:>10}ê°œ                                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

    # DB ì„¸ì…˜
    db = database.SessionLocal()
    timer = BenchmarkTimer()
    
    success_count = 0
    failure_count = 0

    # ë¨¼ì € ê¸°ì¡´ ìœ ì €/ìƒí’ˆ ID ì¡°íšŒ
    try:
        existing_users = db.query(models.User.id).limit(1000).all()
        existing_products = db.query(models.Product.id).limit(1000).all()
        
        if not existing_users or not existing_products:
            print("âŒ ì˜¤ë¥˜: ê¸°ì¡´ ìœ ì €/ìƒí’ˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. initial_seederë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            return None
            
        user_ids = [u[0] for u in existing_users]
        product_ids = [p[0] for p in existing_products]
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return None

    # ì£¼ë¬¸ ìƒì„±ê¸°
    order_gen = OrderGenerator()

    print(f"\nğŸš€ ìˆœì°¨ì²˜ë¦¬ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘... ({TOTAL_RECORDS}ê±´)")
    print("-" * 60)

    timer.start()

    for i in range(TOTAL_RECORDS):
        record_start = time.perf_counter()
        
        try:
            # ëœë¤ ìœ ì €/ìƒí’ˆ ì„ íƒ
            user_id = random.choice(user_ids)
            product_id = random.choice(product_ids)
            
            # ì£¼ë¬¸ ë°ì´í„° ìƒì„±
            order_data = order_gen.generate_single(user_id, product_id)
            
            # ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì‹œë®¬ë ˆì´ì…˜
            simulate_network_delay()
            
            # DBì— ì§ì ‘ ì €ì¥ (ìˆœì°¨ì²˜ë¦¬)
            crud.create_order(db, order_data)
            
            success_count += 1
            
        except Exception as e:
            failure_count += 1
            db.rollback()
            
        record_end = time.perf_counter()
        latency_ms = (record_end - record_start) * 1000
        timer.record_latency(latency_ms)
        
        # ì§„í–‰ë¥  ì¶œë ¥ (10% ë‹¨ìœ„)
        if (i + 1) % (TOTAL_RECORDS // 10) == 0:
            progress = (i + 1) / TOTAL_RECORDS * 100
            current_tps = (i + 1) / (time.perf_counter() - timer.start_time)
            print(f"  â³ {progress:.0f}% ì™„ë£Œ | {i + 1:,}ê±´ | TPS: {current_tps:.1f}")

    timer.stop()

    # ê²°ê³¼ ìƒì„±
    result = BenchmarkResult(
        test_name="ì£¼ë¬¸ ë°ì´í„° ìƒì„±",
        mode="sequential",
        total_records=TOTAL_RECORDS,
        duration_seconds=timer.duration,
        records_per_second=success_count / timer.duration if timer.duration > 0 else 0,
        avg_latency_ms=timer.avg_latency,
        min_latency_ms=timer.min_latency,
        max_latency_ms=timer.max_latency,
        success_count=success_count,
        failure_count=failure_count,
        timestamp=datetime.now().isoformat(),
        extra_info={
            "network_delay_simulated": SIMULATE_NETWORK_DELAY,
            "network_delay_ms": NETWORK_DELAY_MS,
            "batch_size": BATCH_SIZE
        }
    )

    # ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥
    print_result_summary(result)
    save_result(result, "kafka_benchmark")
    
    db.close()
    return result


if __name__ == "__main__":
    result = run_sequential_benchmark()
    if result:
        print("\nâœ… ìˆœì°¨ì²˜ë¦¬ ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")
    else:
        print("\nâŒ ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨")
        sys.exit(1)
