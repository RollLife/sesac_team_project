"""
Kafka ë²¤ì¹˜ë§ˆí¬ í”„ë¡œë“€ì„œ

Kafkaë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ë°œí–‰í•˜ëŠ” ë°©ì‹ì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤.
ë¹„ë™ê¸° ë°œí–‰ì˜ ì¥ì ì„ ë³´ì—¬ì£¼ê¸° ìœ„í•œ ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤.
"""

import os
import sys
import time
import random
import json
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from benchmark_common import BenchmarkResult, BenchmarkTimer, save_result, print_result_summary

from database import database, models
from collect.order_generator import OrderGenerator
from confluent_kafka import Producer


# ë²¤ì¹˜ë§ˆí¬ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ë¡œ ì˜¤ë²„ë¼ì´ë“œ ê°€ëŠ¥)
TOTAL_RECORDS = int(os.environ.get('BENCHMARK_RECORDS', 5000))
KAFKA_BOOTSTRAP_SERVERS = os.environ.get('KAFKA_BOOTSTRAP_SERVERS', 'kafka1:29092,kafka2:29093,kafka3:29094')
KAFKA_TOPIC = os.environ.get('KAFKA_TOPIC_ORDERS', 'orders')


class KafkaBenchmarkProducer:
    """Kafka ë²¤ì¹˜ë§ˆí¬ í”„ë¡œë“€ì„œ"""

    def __init__(self):
        self.producer = Producer({
            'bootstrap.servers': KAFKA_BOOTSTRAP_SERVERS,
            'client.id': 'benchmark-producer',
            'acks': 'all',  # ëª¨ë“  replicaì— ì“°ê¸° ì™„ë£Œ í™•ì¸
            'linger.ms': 5,  # ë°°ì¹˜ ì „ì†¡ ëŒ€ê¸° ì‹œê°„
            'batch.size': 16384,  # ë°°ì¹˜ í¬ê¸°
        })
        self.delivered_count = 0
        self.failed_count = 0
        self.latencies = []

    def delivery_callback(self, err, msg):
        """ë©”ì‹œì§€ ì „ì†¡ ì™„ë£Œ ì½œë°±"""
        if err:
            self.failed_count += 1
        else:
            self.delivered_count += 1

    def produce_message(self, topic: str, data: dict) -> float:
        """ë©”ì‹œì§€ ë°œí–‰ ë° ì§€ì—°ì‹œê°„ ì¸¡ì •"""
        start = time.perf_counter()
        
        message = json.dumps(data, ensure_ascii=False, default=str)
        self.producer.produce(
            topic,
            value=message.encode('utf-8'),
            callback=self.delivery_callback
        )
        
        end = time.perf_counter()
        latency = (end - start) * 1000
        self.latencies.append(latency)
        return latency

    def flush(self):
        """ë‚¨ì€ ë©”ì‹œì§€ ëª¨ë‘ ì „ì†¡"""
        self.producer.flush()


def run_kafka_benchmark():
    """Kafka ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘             Kafka ë²¤ì¹˜ë§ˆí¬ (ë¹„ë™ê¸° ë°œí–‰)                      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  ë ˆì½”ë“œ ìˆ˜: {TOTAL_RECORDS:>10,}ê°œ                                    â•‘
â•‘  Kafka Servers: {KAFKA_BOOTSTRAP_SERVERS[:30]:<30}     â•‘
â•‘  Topic: {KAFKA_TOPIC:<48} â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

    # DB ì„¸ì…˜ (ìœ ì €/ìƒí’ˆ ID ì¡°íšŒìš©)
    db = database.SessionLocal()
    timer = BenchmarkTimer()
    
    # Kafka í”„ë¡œë“€ì„œ
    kafka_producer = KafkaBenchmarkProducer()

    # ê¸°ì¡´ ìœ ì €/ìƒí’ˆ ID ì¡°íšŒ
    try:
        existing_users = db.query(models.User.user_id).limit(1000).all()
        existing_products = db.query(models.Product.product_id).limit(1000).all()
        
        if not existing_users or not existing_products:
            print("âŒ ì˜¤ë¥˜: ê¸°ì¡´ ìœ ì €/ìƒí’ˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. initial_seederë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            return None
            
        user_ids = [u[0] for u in existing_users]
        product_ids = [p[0] for p in existing_products]
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return None

    # ì£¼ë¬¸ ìƒì„±ê¸°
    order_gen = OrderGenerator()

    print(f"\nğŸš€ Kafka ë²¤ì¹˜ë§ˆí¬ ì‹œì‘... ({TOTAL_RECORDS}ê±´)")
    print("-" * 60)

    timer.start()
    produce_start = time.perf_counter()

    for i in range(TOTAL_RECORDS):
        # ëœë¤ ìœ ì €/ìƒí’ˆ ì„ íƒ
        user_id = random.choice(user_ids)
        product_id = random.choice(product_ids)
        
        # ì£¼ë¬¸ ë°ì´í„° ìƒì„±
        order_data = order_gen.generate_single(user_id, product_id)
        
        # Kafka ë©”ì‹œì§€ êµ¬ì„±
        kafka_message = {
            "event_type": "order_created",
            "timestamp": datetime.now().isoformat(),
            "order": order_data
        }
        
        # Kafkaì— ë°œí–‰
        kafka_producer.produce_message(KAFKA_TOPIC, kafka_message)
        
        # ì§„í–‰ë¥  ì¶œë ¥ (10% ë‹¨ìœ„)
        if (i + 1) % (TOTAL_RECORDS // 10) == 0:
            progress = (i + 1) / TOTAL_RECORDS * 100
            current_tps = (i + 1) / (time.perf_counter() - produce_start)
            print(f"  â³ {progress:.0f}% ë°œí–‰ | {i + 1:,}ê±´ | TPS: {current_tps:.1f}")
        
        # ì£¼ê¸°ì ìœ¼ë¡œ poll (ë‚´ë¶€ ì´ë²¤íŠ¸ ì²˜ë¦¬)
        if (i + 1) % 100 == 0:
            kafka_producer.producer.poll(0)

    produce_end = time.perf_counter()
    produce_duration = produce_end - produce_start
    
    print(f"\n  â³ ë©”ì‹œì§€ í”ŒëŸ¬ì‹œ ì¤‘...")
    flush_start = time.perf_counter()
    kafka_producer.flush()
    flush_end = time.perf_counter()
    flush_duration = flush_end - flush_start
    
    timer.stop()

    # ê²°ê³¼ ìƒì„±
    latencies = kafka_producer.latencies
    result = BenchmarkResult(
        test_name="ì£¼ë¬¸ ë°ì´í„° ìƒì„±",
        mode="kafka",
        total_records=TOTAL_RECORDS,
        duration_seconds=timer.duration,
        records_per_second=kafka_producer.delivered_count / timer.duration if timer.duration > 0 else 0,
        avg_latency_ms=sum(latencies) / len(latencies) if latencies else 0,
        min_latency_ms=min(latencies) if latencies else 0,
        max_latency_ms=max(latencies) if latencies else 0,
        success_count=kafka_producer.delivered_count,
        failure_count=kafka_producer.failed_count,
        timestamp=datetime.now().isoformat(),
        extra_info={
            "produce_duration": produce_duration,
            "flush_duration": flush_duration,
            "kafka_servers": KAFKA_BOOTSTRAP_SERVERS,
            "topic": KAFKA_TOPIC
        }
    )

    # ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥
    print_result_summary(result)
    print(f"  â„¹ï¸  ë°œí–‰ ì‹œê°„: {produce_duration:.2f}ì´ˆ")
    print(f"  â„¹ï¸  í”ŒëŸ¬ì‹œ ì‹œê°„: {flush_duration:.2f}ì´ˆ")
    save_result(result, "kafka_benchmark")
    
    db.close()
    return result


if __name__ == "__main__":
    result = run_kafka_benchmark()
    if result:
        print("\nâœ… Kafka ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")
    else:
        print("\nâŒ ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨")
        sys.exit(1)
