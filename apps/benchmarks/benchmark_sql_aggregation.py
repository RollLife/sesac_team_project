"""
PostgreSQL ì§‘ê³„ ë²¤ì¹˜ë§ˆí¬

PostgreSQLì˜ GROUP BYë¥¼ ì‚¬ìš©í•œ ê¸°ë³¸ ì§‘ê³„ ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤.
Spark Streamingê³¼ ë¹„êµí•˜ê¸° ìœ„í•œ ê¸°ì¤€ì„ ì…ë‹ˆë‹¤.
"""

import os
import sys
import time
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from benchmark_common import BenchmarkResult, BenchmarkTimer, save_result, print_result_summary

from sqlalchemy import text
from database import database


# ë²¤ì¹˜ë§ˆí¬ ì„¤ì •
NUM_ITERATIONS = int(os.environ.get('BENCHMARK_ITERATIONS', 10))  # ë°˜ë³µ íšŸìˆ˜


# ì§‘ê³„ ì¿¼ë¦¬ ì •ì˜
AGGREGATION_QUERIES = {
    "category_revenue": """
        SELECT 
            p.category,
            COUNT(o.id) as order_count,
            SUM(o.total_amount) as total_revenue,
            AVG(o.total_amount) as avg_order_value
        FROM orders o
        JOIN products p ON o.product_id = p.id
        GROUP BY p.category
        ORDER BY total_revenue DESC
    """,
    
    "payment_stats": """
        SELECT 
            payment_method,
            COUNT(*) as count,
            SUM(total_amount) as total_revenue,
            AVG(total_amount) as avg_amount
        FROM orders
        GROUP BY payment_method
        ORDER BY count DESC
    """,
    
    "hourly_orders": """
        SELECT 
            DATE_TRUNC('hour', created_at) as hour,
            COUNT(*) as order_count,
            SUM(total_amount) as revenue
        FROM orders
        WHERE created_at >= NOW() - INTERVAL '24 hours'
        GROUP BY DATE_TRUNC('hour', created_at)
        ORDER BY hour DESC
    """,
    
    "user_stats": """
        SELECT 
            u.grade,
            COUNT(DISTINCT o.user_id) as unique_users,
            COUNT(o.id) as total_orders,
            SUM(o.total_amount) as total_spent,
            AVG(o.total_amount) as avg_order
        FROM orders o
        JOIN users u ON o.user_id = u.id
        GROUP BY u.grade
        ORDER BY total_spent DESC
    """,
    
    "top_products": """
        SELECT 
            p.name as product_name,
            p.category,
            COUNT(o.id) as order_count,
            SUM(o.total_amount) as total_revenue
        FROM orders o
        JOIN products p ON o.product_id = p.id
        GROUP BY p.id, p.name, p.category
        ORDER BY order_count DESC
        LIMIT 20
    """,
    
    "daily_trend": """
        SELECT 
            DATE(created_at) as date,
            COUNT(*) as order_count,
            SUM(total_amount) as daily_revenue,
            COUNT(DISTINCT user_id) as unique_buyers
        FROM orders
        WHERE created_at >= NOW() - INTERVAL '30 days'
        GROUP BY DATE(created_at)
        ORDER BY date DESC
    """
}


def run_sql_benchmark():
    """PostgreSQL ì§‘ê³„ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           PostgreSQL ì§‘ê³„ ë²¤ì¹˜ë§ˆí¬                           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  ì§‘ê³„ ì¿¼ë¦¬ ìˆ˜: {len(AGGREGATION_QUERIES):>10}ê°œ                                â•‘
â•‘  ë°˜ë³µ íšŸìˆ˜: {NUM_ITERATIONS:>10}íšŒ                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

    db = database.SessionLocal()
    timer = BenchmarkTimer()
    
    query_results = {}
    total_rows = 0

    # ë¨¼ì € orders í…Œì´ë¸” ë ˆì½”ë“œ ìˆ˜ í™•ì¸
    try:
        count_result = db.execute(text("SELECT COUNT(*) FROM orders")).scalar()
        print(f"ğŸ“Š orders í…Œì´ë¸” ë ˆì½”ë“œ ìˆ˜: {count_result:,}ê±´")
        total_rows = count_result
    except Exception as e:
        print(f"âŒ í…Œì´ë¸” ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return None

    print(f"\nğŸš€ PostgreSQL ì§‘ê³„ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘...")
    print("-" * 60)

    timer.start()
    all_latencies = []

    for iteration in range(NUM_ITERATIONS):
        iteration_start = time.perf_counter()
        
        for query_name, query in AGGREGATION_QUERIES.items():
            query_start = time.perf_counter()
            
            try:
                result = db.execute(text(query))
                rows = result.fetchall()
                
                if query_name not in query_results:
                    query_results[query_name] = {
                        'row_count': len(rows),
                        'latencies': []
                    }
                
            except Exception as e:
                print(f"âŒ ì¿¼ë¦¬ ì˜¤ë¥˜ ({query_name}): {e}")
                continue
            
            query_end = time.perf_counter()
            latency = (query_end - query_start) * 1000
            query_results[query_name]['latencies'].append(latency)
            all_latencies.append(latency)
        
        iteration_end = time.perf_counter()
        iteration_time = (iteration_end - iteration_start) * 1000
        
        # ì§„í–‰ë¥  ì¶œë ¥
        if (iteration + 1) % max(1, NUM_ITERATIONS // 5) == 0:
            progress = (iteration + 1) / NUM_ITERATIONS * 100
            print(f"  â³ {progress:.0f}% ì™„ë£Œ | ë°˜ë³µ {iteration + 1}/{NUM_ITERATIONS} | {iteration_time:.1f}ms")

    timer.stop()

    # ì¿¼ë¦¬ë³„ ê²°ê³¼ ìš”ì•½
    print(f"\n{'='*60}")
    print("ì¿¼ë¦¬ë³„ ì„±ëŠ¥ ë¶„ì„")
    print(f"{'='*60}")
    print(f"{'ì¿¼ë¦¬ëª…':<20} {'ê²°ê³¼í–‰':<8} {'í‰ê· (ms)':<10} {'ìµœì†Œ(ms)':<10} {'ìµœëŒ€(ms)':<10}")
    print("-" * 60)
    
    for query_name, data in query_results.items():
        latencies = data['latencies']
        if latencies:
            avg_lat = sum(latencies) / len(latencies)
            min_lat = min(latencies)
            max_lat = max(latencies)
            print(f"{query_name:<20} {data['row_count']:<8} {avg_lat:<10.2f} {min_lat:<10.2f} {max_lat:<10.2f}")

    # ê²°ê³¼ ìƒì„±
    total_queries = len(AGGREGATION_QUERIES) * NUM_ITERATIONS
    result = BenchmarkResult(
        test_name="PostgreSQL ì§‘ê³„ ì¿¼ë¦¬",
        mode="sql",
        total_records=total_queries,
        duration_seconds=timer.duration,
        records_per_second=total_queries / timer.duration if timer.duration > 0 else 0,
        avg_latency_ms=sum(all_latencies) / len(all_latencies) if all_latencies else 0,
        min_latency_ms=min(all_latencies) if all_latencies else 0,
        max_latency_ms=max(all_latencies) if all_latencies else 0,
        success_count=total_queries,
        failure_count=0,
        timestamp=datetime.now().isoformat(),
        extra_info={
            "query_count": len(AGGREGATION_QUERIES),
            "iterations": NUM_ITERATIONS,
            "total_orders": total_rows,
            "query_stats": {
                name: {
                    'avg_ms': sum(data['latencies']) / len(data['latencies']) if data['latencies'] else 0,
                    'row_count': data['row_count']
                }
                for name, data in query_results.items()
            }
        }
    )

    # ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥
    print_result_summary(result)
    save_result(result, "spark_benchmark")
    
    db.close()
    return result


if __name__ == "__main__":
    result = run_sql_benchmark()
    if result:
        print("\nâœ… PostgreSQL ì§‘ê³„ ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")
    else:
        print("\nâŒ ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨")
        sys.exit(1)
