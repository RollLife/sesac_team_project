{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae855295",
   "metadata": {},
   "source": [
    "## ğŸ§ª Spark Streaming ë¡œì§ í…ŒìŠ¤íŠ¸ ë…¸íŠ¸ë¶\n",
    "ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ì„ ëŒë¦¬ê¸° ì „ì—, Kafkaì—ì„œ ë°ì´í„°ë¥¼ ì˜ ê°€ì ¸ì˜¤ëŠ”ì§€, íŒŒì‹±ì€ ì˜ ë˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” ìš©ë„ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6c2433",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° ì„¸ì…˜ ìƒì„±\n",
    "import os\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# í•„ìˆ˜ íŒ¨í‚¤ì§€ ë¡œë”© (Kafka, PostgreSQL)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TestNotebook\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.postgresql:postgresql:42.6.0\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark Session Created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31924a75",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 2. ìŠ¤í‚¤ë§ˆ ì •ì˜ (streaming_analysis.pyì™€ ë™ì¼í•´ì•¼ í•¨)\n",
    "order_details_schema = StructType() \\\n",
    "    .add(\"order_id\", StringType()) \\\n",
    "    .add(\"user_id\", StringType()) \\\n",
    "    .add(\"product_id\", StringType()) \\\n",
    "    .add(\"category\", StringType()) \\\n",
    "    .add(\"quantity\", IntegerType()) \\\n",
    "    .add(\"total_amount\", IntegerType()) \\\n",
    "    .add(\"payment_method\", StringType()) \\\n",
    "    .add(\"user_region\", StringType()) \\\n",
    "    .add(\"user_age_group\", StringType()) \\\n",
    "    .add(\"created_at\", TimestampType())\n",
    "\n",
    "final_schema = StructType() \\\n",
    "    .add(\"event_type\", StringType()) \\\n",
    "    .add(\"timestamp\", StringType()) \\\n",
    "    .add(\"order\", order_details_schema)\n",
    "\n",
    "print(\"Schema Defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92e39b4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 3. Kafka ë°ì´í„° ì½ê¸° (Batch Mode)\n",
    "# ì¤‘ìš”: readStreamì´ ì•„ë‹ˆë¼ readë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. (í˜„ì¬ ìŒ“ì—¬ìˆëŠ” ë°ì´í„°ë§Œ ê°€ì ¸ì˜´)\n",
    "df_raw = spark.read \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka1:29092,kafka2:29093,kafka3:29094\") \\\n",
    "    .option(\"subscribe\", \"orders\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()\n",
    "\n",
    "print(f\"Raw Data Count: {df_raw.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebc0153",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 4. ë°ì´í„° íŒŒì‹± í…ŒìŠ¤íŠ¸\n",
    "# ì—¬ê¸°ì„œ nullì´ ë‚˜ì˜¤ë©´ ìŠ¤í‚¤ë§ˆê°€ í‹€ë¦° ê²ƒ!\n",
    "df_parsed = df_raw.selectExpr(\"CAST(value AS STRING) as json_str\") \\\n",
    "    .select(from_json(col(\"json_str\"), final_schema).alias(\"data\")) \\\n",
    "    .select(\"data.order.*\")\n",
    "\n",
    "# ë°ì´í„° ëˆˆìœ¼ë¡œ í™•ì¸\n",
    "df_parsed.show(5, truncate=False)\n",
    "df_parsed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a37ad91",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 5. [í…ŒìŠ¤íŠ¸ 1] ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ ì§‘ê³„ í…ŒìŠ¤íŠ¸\n",
    "# ìœˆë„ìš° ì§‘ê³„ê°€ ì˜ ë˜ëŠ”ì§€ í™•ì¸\n",
    "df_category = df_parsed \\\n",
    "    .groupBy(window(\"created_at\", \"1 minute\"), \"category\") \\\n",
    "    .agg(count(\"order_id\").alias(\"count\"), sum(\"total_amount\").alias(\"revenue\")) \\\n",
    "    .orderBy(\"window\", \"category\")\n",
    "\n",
    "print(\"=== ì¹´í…Œê³ ë¦¬ë³„ ì§‘ê³„ ê²°ê³¼ ===\")\n",
    "df_category.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aff9ca",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 6. [í…ŒìŠ¤íŠ¸ 2] ì—°ë ¹ëŒ€ë³„ ì§‘ê³„ í…ŒìŠ¤íŠ¸\n",
    "df_age = df_parsed \\\n",
    "    .groupBy(\"user_age_group\") \\\n",
    "    .agg(count(\"order_id\").alias(\"count\")) \\\n",
    "    .orderBy(\"user_age_group\")\n",
    "\n",
    "print(\"=== ì—°ë ¹ëŒ€ë³„ ì£¼ë¬¸ ìˆ˜ ===\")\n",
    "df_age.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120dcf94",
   "metadata": {},
   "source": [
    "### âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ\n",
    "ìœ„ ê²°ê³¼ê°€ ì •ìƒì ìœ¼ë¡œ ë‚˜ì˜¨ë‹¤ë©´ `streaming_analysis.py`ë¥¼ ì‹¤í–‰í•´ë„ ì¢‹ìŠµë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
