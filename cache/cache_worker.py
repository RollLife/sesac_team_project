"""
ë°±ê·¸ë¼ìš´ë“œ ìºì‹œ ì›Œì»¤ (Aging ê¸°ë²•)

- 50ì´ˆ ì£¼ê¸°ë¡œ DBì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ Redis ìºì‹œ ê°±ì‹ 
- Aging ê¸°ë²•: ì‹ ê·œ 50% + ì˜¤ë˜ëœ ê²ƒ 50% ë¹„ìœ¨ë¡œ ê°€ì ¸ì˜´
- ê¸°ì•„í˜„ìƒ ë°©ì§€: ëª¨ë“  ë°ì´í„°ê°€ ìˆœí™˜ë  ê¸°íšŒ ì œê³µ
"""

import os
import sys
import time
import logging
from datetime import datetime
from typing import List, Dict, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from sqlalchemy.orm import Session

from database.database import SessionLocal
from database.models import User, Product
from cache.client import get_redis_client
from cache.config import CACHE_CONFIG, REDIS_ENABLED

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class CacheWorker:
    """Redis ìºì‹œ ê°±ì‹  ì›Œì»¤ (Aging ê¸°ë²• ì ìš©)"""

    def __init__(self):
        self.redis_client = get_redis_client()
        self.refresh_interval = CACHE_CONFIG['refresh_interval']  # 50ì´ˆ
        self.batch_size = CACHE_CONFIG['batch_size']  # 1000ê°œ
        self.running = True

        # í†µê³„
        self.stats = {
            'users_cached': 0,
            'products_cached': 0,
            'refresh_count': 0,
            'start_time': None,
        }

    def fetch_users_with_aging(self, db: Session) -> List[Dict[str, Any]]:
        """
        Aging ê¸°ë²•ìœ¼ë¡œ ìœ ì € ë°ì´í„° ì¡°íšŒ
        - last_cached_at IS NULL (ë¯¸ìºì‹±) ìš°ì„ , ê·¸ ë‹¤ìŒ last_cached_at ì˜¤ë˜ëœ ìˆœ
        - í•­ìƒ batch_size(1000)ê°œë¥¼ ê°€ì ¸ì™€ì„œ í…Œì´ë¸” ì „ì²´ë¥¼ ìˆœí™˜
        """
        fetched_users = db.query(User).order_by(
            User.last_cached_at.asc().nullsfirst()
        ).limit(self.batch_size).all()

        users = []
        user_ids = []
        for user in fetched_users:
            users.append(self._user_to_dict(user))
            user_ids.append(user.user_id)

        if user_ids:
            now = datetime.now()
            db.query(User).filter(
                User.user_id.in_(user_ids)
            ).update(
                {User.last_cached_at: now},
                synchronize_session=False
            )
            db.commit()

        logger.info(f"ìœ ì € ì¡°íšŒ ì™„ë£Œ: ì´ {len(users)}ëª…")
        return users

    def fetch_products_with_aging(self, db: Session) -> List[Dict[str, Any]]:
        """
        Aging ê¸°ë²•ìœ¼ë¡œ ìƒí’ˆ ë°ì´í„° ì¡°íšŒ
        - last_cached_at IS NULL (ë¯¸ìºì‹±) ìš°ì„ , ê·¸ ë‹¤ìŒ last_cached_at ì˜¤ë˜ëœ ìˆœ
        - í•­ìƒ batch_size(1000)ê°œë¥¼ ê°€ì ¸ì™€ì„œ í…Œì´ë¸” ì „ì²´ë¥¼ ìˆœí™˜
        """
        fetched_products = db.query(Product).order_by(
            Product.last_cached_at.asc().nullsfirst()
        ).limit(self.batch_size).all()

        products = []
        product_ids = []
        for product in fetched_products:
            products.append(self._product_to_dict(product))
            product_ids.append(product.product_id)

        if product_ids:
            now = datetime.now()
            db.query(Product).filter(
                Product.product_id.in_(product_ids)
            ).update(
                {Product.last_cached_at: now},
                synchronize_session=False
            )
            db.commit()

        logger.info(f"ìƒí’ˆ ì¡°íšŒ ì™„ë£Œ: ì´ {len(products)}ê°œ")
        return products

    def _user_to_dict(self, user: User) -> Dict[str, Any]:
        """User ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            'user_id': user.user_id,
            'name': user.name,
            'gender': user.gender,
            'age': user.age,
            'birth_year': user.birth_year,
            'address': user.address,
            'address_district': user.address_district,
            'email': user.email,
            'grade': user.grade,
            'created_at': user.created_at.isoformat() if user.created_at else None,
        }

    def _product_to_dict(self, product: Product) -> Dict[str, Any]:
        """Product ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            'product_id': product.product_id,
            'category': product.category,
            'name': product.name,
            'org_price': product.org_price,
            'price': product.price,
            'discount_rate': product.discount_rate,
            'description': product.description,
            'brand': product.brand,
            'stock': product.stock,
            'created_at': product.created_at.isoformat() if product.created_at else None,
        }

    def refresh_cache(self):
        """ìºì‹œ ê°±ì‹  (1íšŒ ì‹¤í–‰)"""
        db = SessionLocal()
        try:
            # 1. DBì—ì„œ Aging ê¸°ë²•ìœ¼ë¡œ ë°ì´í„° ì¡°íšŒ
            users = self.fetch_users_with_aging(db)
            products = self.fetch_products_with_aging(db)

            # 2. Redisì— ìºì‹œ ì €ì¥
            if users:
                self.redis_client.set_users_cache(users)
                self.stats['users_cached'] = len(users)

            if products:
                self.redis_client.set_products_cache(products)
                self.stats['products_cached'] = len(products)

            self.stats['refresh_count'] += 1

            # 3. í†µê³„ ë¡œê·¸
            logger.info(
                f"ìºì‹œ ê°±ì‹  #{self.stats['refresh_count']} ì™„ë£Œ - "
                f"ìœ ì €: {len(users)}ëª…, ìƒí’ˆ: {len(products)}ê°œ"
            )

        except Exception as e:
            logger.error(f"ìºì‹œ ê°±ì‹  ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
        finally:
            db.close()

    def start(self):
        """ì›Œì»¤ ì‹œì‘ (ë¬´í•œ ë£¨í”„)"""
        if not REDIS_ENABLED:
            logger.error("Redisê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤ (REDIS_ENABLED=false)")
            return

        if not self.redis_client.is_connected():
            logger.error("Redis ì—°ê²° ì‹¤íŒ¨. ì›Œì»¤ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘            Redis ìºì‹œ ì›Œì»¤ (Aging ê¸°ë²•)                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """)
        print(f"ğŸ“‹ ì„¤ì •:")
        print(f"  - ê°±ì‹  ì£¼ê¸°: {self.refresh_interval}ì´ˆ")
        print(f"  - ë°°ì¹˜ í¬ê¸°: {self.batch_size}ê°œ")
        print(f"  - Ctrl+Cë¡œ ì¤‘ì§€\n")

        self.stats['start_time'] = time.time()

        # ìµœì´ˆ 1íšŒ ì¦‰ì‹œ ì‹¤í–‰
        logger.info("ìµœì´ˆ ìºì‹œ ë¡œë“œ ì‹œì‘...")
        self.refresh_cache()

        try:
            while self.running:
                # ê°±ì‹  ì£¼ê¸°ë§Œí¼ ëŒ€ê¸°
                time.sleep(self.refresh_interval)

                if not self.running:
                    break

                # ìºì‹œ ê°±ì‹ 
                self.refresh_cache()

        except KeyboardInterrupt:
            logger.info("ì¢…ë£Œ ì‹ í˜¸ ìˆ˜ì‹ ...")
            self.running = False

        # ìµœì¢… í†µê³„
        elapsed = time.time() - self.stats['start_time']
        print(f"\n{'='*60}")
        print(f"ğŸ“Š ìµœì¢… í†µê³„")
        print(f"{'='*60}")
        print(f"  ì´ ì‹¤í–‰ ì‹œê°„: {elapsed:.1f}ì´ˆ ({elapsed/60:.1f}ë¶„)")
        print(f"  ê°±ì‹  íšŸìˆ˜: {self.stats['refresh_count']}íšŒ")
        print(f"  ë§ˆì§€ë§‰ ìºì‹œ: ìœ ì € {self.stats['users_cached']}ëª…, ìƒí’ˆ {self.stats['products_cached']}ê°œ")
        print(f"{'='*60}\n")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    worker = CacheWorker()
    worker.start()


if __name__ == "__main__":
    main()
