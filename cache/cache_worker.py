"""
ë°±ê·¸ë¼ìš´ë“œ ìºì‹œ ì›Œì»¤

- 50ì´ˆ ì£¼ê¸°ë¡œ DBì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ Redis ìºì‹œ ê°±ì‹ 
- ê³ ê°: êµ¬ë§¤ì´ë ¥ ê³ ê° 600ëª… + ë¯¸êµ¬ë§¤ ê³ ê° 400ëª…
- ìƒí’ˆ: íŒë§¤ìœ¨ ë†’ì€ ìƒí’ˆ 700ê°œ + ì‹ ìƒí’ˆ 300ê°œ
"""

import os
import sys
import time
import logging
from datetime import datetime
from typing import List, Dict, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from sqlalchemy.orm import Session

from database.database import SessionLocal
from database.models import User, Product
from cache.client import get_redis_client
from cache.config import CACHE_CONFIG, REDIS_ENABLED

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class CacheWorker:
    """Redis ìºì‹œ ê°±ì‹  ì›Œì»¤ (êµ¬ë§¤ì´ë ¥/ë¯¸êµ¬ë§¤ ë¶„ë¦¬ ì ì¬)"""

    # ê³ ê° ìºì‹œ ë¹„ìœ¨
    USER_PURCHASED_LIMIT = 600
    USER_NEW_LIMIT = 400

    # ìƒí’ˆ ìºì‹œ ë¹„ìœ¨
    PRODUCT_POPULAR_LIMIT = 700
    PRODUCT_NEW_LIMIT = 300

    def __init__(self):
        self.redis_client = get_redis_client()
        self.refresh_interval = CACHE_CONFIG['refresh_interval']  # 50ì´ˆ
        self.batch_size = CACHE_CONFIG['batch_size']  # 1000ê°œ
        self.running = True

        # í†µê³„
        self.stats = {
            'users_cached': 0,
            'products_cached': 0,
            'refresh_count': 0,
            'start_time': None,
        }

    def fetch_users(self, db: Session) -> List[Dict[str, Any]]:
        """
        êµ¬ë§¤ì´ë ¥/ë¯¸êµ¬ë§¤ ë¶„ë¦¬ ì ì¬ë¡œ ìœ ì € ë°ì´í„° ì¡°íšŒ
        - êµ¬ë§¤ì´ë ¥ ê³ ê°: last_ordered_at ì˜¤ë˜ëœ ìˆœ (ê¸°ë³¸ 600ëª…)
        - ë¯¸êµ¬ë§¤ ê³ ê°: created_at ìµœì‹ ìˆœ (ìµœëŒ€ 400ëª…)
        - ë¯¸êµ¬ë§¤ ë¶€ì¡± ì‹œ êµ¬ë§¤ì´ë ¥ í’€ í™•ëŒ€, í•©ê³„ í•­ìƒ 1000ëª…
        """
        # 1. ë¯¸êµ¬ë§¤ ê³ ê° (ìµœëŒ€ 400ëª…, created_at ìµœì‹ ìˆœ)
        new_users = db.query(User).filter(
            User.last_ordered_at.is_(None)
        ).order_by(
            User.created_at.desc()
        ).limit(self.USER_NEW_LIMIT).all()

        # 2. ë¯¸êµ¬ë§¤ ë¶€ì¡±ë¶„ë§Œí¼ êµ¬ë§¤ì´ë ¥ í’€ í™•ëŒ€
        purchased_limit = self.batch_size - len(new_users)

        # 3. êµ¬ë§¤ì´ë ¥ ê³ ê° (last_ordered_at ì˜¤ë˜ëœ ìˆœ)
        purchased_users = db.query(User).filter(
            User.last_ordered_at.isnot(None)
        ).order_by(
            User.last_ordered_at.asc()
        ).limit(purchased_limit).all()

        # 4. í•©ì¹˜ê¸°
        all_users = purchased_users + new_users
        users = [self._user_to_dict(user) for user in all_users]

        logger.info(
            f"ìœ ì € ì¡°íšŒ ì™„ë£Œ: êµ¬ë§¤ì´ë ¥ {len(purchased_users)}ëª… + "
            f"ë¯¸êµ¬ë§¤ {len(new_users)}ëª… = ì´ {len(users)}ëª…"
        )
        return users

    def fetch_products(self, db: Session) -> List[Dict[str, Any]]:
        """
        íŒë§¤ìœ¨/ì‹ ìƒí’ˆ ë¶„ë¦¬ ì ì¬ë¡œ ìƒí’ˆ ë°ì´í„° ì¡°íšŒ
        - íŒë§¤ìœ¨ ë†’ì€ ìƒí’ˆ: order_count ë†’ì€ ìˆœ (ê¸°ë³¸ 700ê°œ)
        - ì‹ ìƒí’ˆ: order_count == 0, created_at ìµœì‹ ìˆœ (ìµœëŒ€ 300ê°œ)
        - ì‹ ìƒí’ˆ ë¶€ì¡± ì‹œ íŒë§¤ ìƒí’ˆ í’€ í™•ëŒ€, í•©ê³„ í•­ìƒ 1000ê°œ
        """
        # 1. ì‹ ìƒí’ˆ (ìµœëŒ€ 300ê°œ, created_at ìµœì‹ ìˆœ)
        new_products = db.query(Product).filter(
            Product.order_count == 0
        ).order_by(
            Product.created_at.desc()
        ).limit(self.PRODUCT_NEW_LIMIT).all()

        # 2. ì‹ ìƒí’ˆ ë¶€ì¡±ë¶„ë§Œí¼ íŒë§¤ ìƒí’ˆ í’€ í™•ëŒ€
        popular_limit = self.batch_size - len(new_products)

        # 3. íŒë§¤ìœ¨ ë†’ì€ ìƒí’ˆ (order_count ë†’ì€ ìˆœ)
        popular_products = db.query(Product).filter(
            Product.order_count > 0
        ).order_by(
            Product.order_count.desc()
        ).limit(popular_limit).all()

        # 4. í•©ì¹˜ê¸°
        all_products = popular_products + new_products
        products = [self._product_to_dict(product) for product in all_products]

        logger.info(
            f"ìƒí’ˆ ì¡°íšŒ ì™„ë£Œ: ì¸ê¸° {len(popular_products)}ê°œ + "
            f"ì‹ ìƒí’ˆ {len(new_products)}ê°œ = ì´ {len(products)}ê°œ"
        )
        return products

    def _user_to_dict(self, user: User) -> Dict[str, Any]:
        """User ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (êµ¬ë§¤ ì„±í–¥ ê³„ì‚°ì— í•„ìš”í•œ í•„ë“œ í¬í•¨)"""
        return {
            'user_id': user.user_id,
            'name': user.name,
            'gender': user.gender,
            'age': user.age,
            'birth_year': user.birth_year,
            'address': user.address,
            'address_district': user.address_district,
            'email': user.email,
            'grade': user.grade,
            'status': user.status,
            'marketing_agree': user.marketing_agree,
            'last_ordered_at': user.last_ordered_at.isoformat() if user.last_ordered_at else None,
            'random_seed': user.random_seed,
            'created_at': user.created_at.isoformat() if user.created_at else None,
        }

    def _product_to_dict(self, product: Product) -> Dict[str, Any]:
        """Product ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            'product_id': product.product_id,
            'category': product.category,
            'name': product.name,
            'org_price': product.org_price,
            'price': product.price,
            'discount_rate': product.discount_rate,
            'description': product.description,
            'brand': product.brand,
            'stock': product.stock,
            'order_count': product.order_count,
            'created_at': product.created_at.isoformat() if product.created_at else None,
        }

    def refresh_cache(self):
        """ìºì‹œ ê°±ì‹  (1íšŒ ì‹¤í–‰)"""
        db = SessionLocal()
        try:
            # 1. DBì—ì„œ êµ¬ë§¤ì´ë ¥/ë¯¸êµ¬ë§¤ ë¶„ë¦¬ ì ì¬ë¡œ ë°ì´í„° ì¡°íšŒ
            users = self.fetch_users(db)
            products = self.fetch_products(db)

            # 2. Redisì— ìºì‹œ ì €ì¥
            if users:
                self.redis_client.set_users_cache(users)
                self.stats['users_cached'] = len(users)

            if products:
                self.redis_client.set_products_cache(products)
                self.stats['products_cached'] = len(products)

            self.stats['refresh_count'] += 1

            # 3. í†µê³„ ë¡œê·¸
            logger.info(
                f"ìºì‹œ ê°±ì‹  #{self.stats['refresh_count']} ì™„ë£Œ - "
                f"ìœ ì €: {len(users)}ëª…, ìƒí’ˆ: {len(products)}ê°œ"
            )

        except Exception as e:
            logger.error(f"ìºì‹œ ê°±ì‹  ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
        finally:
            db.close()

    def start(self):
        """ì›Œì»¤ ì‹œì‘ (ë¬´í•œ ë£¨í”„)"""
        if not REDIS_ENABLED:
            logger.error("Redisê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤ (REDIS_ENABLED=false)")
            return

        if not self.redis_client.is_connected():
            logger.error("Redis ì—°ê²° ì‹¤íŒ¨. ì›Œì»¤ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     Redis ìºì‹œ ì›Œì»¤ (êµ¬ë§¤ì´ë ¥/ë¯¸êµ¬ë§¤ ë¶„ë¦¬ ì ì¬)              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """)
        print(f"ğŸ“‹ ì„¤ì •:")
        print(f"  - ê°±ì‹  ì£¼ê¸°: {self.refresh_interval}ì´ˆ")
        print(f"  - ë°°ì¹˜ í¬ê¸°: {self.batch_size}ê°œ")
        print(f"  - Ctrl+Cë¡œ ì¤‘ì§€\n")

        self.stats['start_time'] = time.time()

        # ìµœì´ˆ 1íšŒ ì¦‰ì‹œ ì‹¤í–‰
        logger.info("ìµœì´ˆ ìºì‹œ ë¡œë“œ ì‹œì‘...")
        self.refresh_cache()

        try:
            while self.running:
                # ê°±ì‹  ì£¼ê¸°ë§Œí¼ ëŒ€ê¸°
                time.sleep(self.refresh_interval)

                if not self.running:
                    break

                # ìºì‹œ ê°±ì‹ 
                self.refresh_cache()

        except KeyboardInterrupt:
            logger.info("ì¢…ë£Œ ì‹ í˜¸ ìˆ˜ì‹ ...")
            self.running = False

        # ìµœì¢… í†µê³„
        elapsed = time.time() - self.stats['start_time']
        print(f"\n{'='*60}")
        print(f"ğŸ“Š ìµœì¢… í†µê³„")
        print(f"{'='*60}")
        print(f"  ì´ ì‹¤í–‰ ì‹œê°„: {elapsed:.1f}ì´ˆ ({elapsed/60:.1f}ë¶„)")
        print(f"  ê°±ì‹  íšŸìˆ˜: {self.stats['refresh_count']}íšŒ")
        print(f"  ë§ˆì§€ë§‰ ìºì‹œ: ìœ ì € {self.stats['users_cached']}ëª…, ìƒí’ˆ {self.stats['products_cached']}ê°œ")
        print(f"{'='*60}\n")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    worker = CacheWorker()
    worker.start()


if __name__ == "__main__":
    main()
