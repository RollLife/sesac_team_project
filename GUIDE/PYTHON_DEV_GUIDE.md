# Python ê°œë°œ/í…ŒìŠ¤íŠ¸ ì»¨í…Œì´ë„ˆ ê°€ì´ë“œ

## ê°œìš”

`python-dev` ì»¨í…Œì´ë„ˆëŠ” Docker í™˜ê²½ì—ì„œ Python ì½”ë“œë¥¼ ëŒ€í™”í˜•ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•˜ê³  ê°œë°œí•  ìˆ˜ ìˆëŠ” í™˜ê²½ì„ ì œê³µí•©ë‹ˆë‹¤.

### ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ (Redis ìºì‹± + Aging)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQL  â”‚â”€â”€â”€â”€â–¶â”‚Cache-Worker â”‚â”€â”€â”€â”€â–¶â”‚    Redis    â”‚
â”‚  (ì›ë³¸ DB)  â”‚     â”‚(Aging 50ì´ˆ) â”‚     â”‚ (1000ê±´)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Producer   â”‚â”€â”€â”€â”€â–¶â”‚   Kafka     â”‚â”€â”€â”€â”€â–¶â”‚  Consumers  â”‚
â”‚(Redisì¡°íšŒ)  â”‚     â”‚ (3 brokers) â”‚     â”‚(9 instances)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚
                                               â–¼
                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                        â”‚ PostgreSQL  â”‚
                                        â”‚   (ì €ì¥)    â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ì£¼ìš” ê¸°ëŠ¥

- âœ… PostgreSQL, Kafka, **Redis** ì—°ê²° í…ŒìŠ¤íŠ¸
- âœ… Python ëŒ€í™”í˜• ì‰˜ (REPL)
- âœ… ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ë° ë””ë²„ê¹…
- âœ… ì½”ë“œ ë³€ê²½ ì‹¤ì‹œê°„ ë°˜ì˜ (ë³¼ë¥¨ ë§ˆìš´íŠ¸)
- âœ… í™˜ê²½ í™•ì¸ ë° ê²€ì¦
- âœ… **Redis ìºì‹œ í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸**

## ì‹œì‘í•˜ê¸°

### 1. ì»¨í…Œì´ë„ˆ ì‹¤í–‰

```bash
# í”„ë¡œíŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰
docker-compose --profile dev up -d python-dev

# ë˜ëŠ” ì§ì ‘ ì‹¤í–‰
docker-compose up -d python-dev
```

### 2. ì»¨í…Œì´ë„ˆ ì ‘ì†

```bash
# Bash ì‰˜ ì ‘ì†
docker-compose exec python-dev bash

# ë˜ëŠ”
docker exec -it python_dev bash
```

## í™˜ê²½ í…ŒìŠ¤íŠ¸

### ìë™ í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ
python tests/test_environment.py
```

**ì¶œë ¥ ì˜ˆì‹œ:**
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              í™˜ê²½ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

============================================================
1. í™˜ê²½ë³€ìˆ˜ í™•ì¸
============================================================

âœ… DB_TYPE = local
âœ… POSTGRES_HOST = postgres
âœ… POSTGRES_PORT = 5432
âœ… KAFKA_BOOTSTRAP_SERVERS = kafka1:29092,kafka2:29093,kafka3:29094
âœ… REDIS_HOST = redis
âœ… REDIS_PORT = 6379

...

============================================================
í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½
============================================================

âœ… í™˜ê²½ë³€ìˆ˜: ì„±ê³µ
âœ… Python íŒ¨í‚¤ì§€: ì„±ê³µ
âœ… PostgreSQL: ì„±ê³µ
âœ… Kafka ì—°ê²°: ì„±ê³µ
âœ… Kafka Producer: ì„±ê³µ
âœ… Redis ì—°ê²°: ì„±ê³µ
âœ… ë°ì´í„° ìƒì„±ê¸°: ì„±ê³µ

âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! (7/7)
âœ… í™˜ê²½ì´ ì •ìƒì ìœ¼ë¡œ êµ¬ì„±ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰
```

### ìˆ˜ë™ í…ŒìŠ¤íŠ¸

#### PostgreSQL ì—°ê²° í™•ì¸
```bash
docker-compose exec python-dev python -c "
from database.database import engine
from sqlalchemy import text
with engine.connect() as conn:
    result = conn.execute(text('SELECT version();'))
    print(result.fetchone()[0])
"
```

#### Kafka ì—°ê²° í™•ì¸
```bash
docker-compose exec python-dev python -c "
from confluent_kafka.admin import AdminClient
from kafka.config import KAFKA_BOOTSTRAP_SERVERS
admin = AdminClient({'bootstrap.servers': KAFKA_BOOTSTRAP_SERVERS})
metadata = admin.list_topics(timeout=10)
print(f'ë¸Œë¡œì»¤ ìˆ˜: {len(metadata.brokers)}')
print(f'í† í”½ ìˆ˜: {len(metadata.topics)}')
"
```

#### Redis ì—°ê²° í™•ì¸
```bash
docker-compose exec python-dev python -c "
from cache.client import get_redis_client
client = get_redis_client()
if client.is_connected():
    print('Redis ì—°ê²° ì„±ê³µ!')
    user = client.get_random_user()
    print(f'ëœë¤ ìœ ì €: {user}')
"
```

## Redis ìºì‹œ í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸

### ê¸°ë³¸ ì‚¬ìš©ë²•

```python
# Python ì‰˜ì—ì„œ
from cache.client import get_redis_client

# í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸° (ì‹±ê¸€í†¤)
redis_client = get_redis_client()

# ì—°ê²° ìƒíƒœ í™•ì¸
if redis_client.is_connected():
    print("Redis ì—°ê²°ë¨")

# ëœë¤ ìœ ì € ì¡°íšŒ
user = redis_client.get_random_user()
print(user)  # {'user_id': 'u_123', 'name': 'í™ê¸¸ë™', ...}

# ëœë¤ ìƒí’ˆ ì¡°íšŒ
product = redis_client.get_random_product()
print(product)  # {'product_id': 'p_456', 'name': 'ë¬´ì„  ì´ì–´í°', ...}
```

### ìºì‹œ ìƒíƒœ í™•ì¸

```bash
# Redis CLIë¡œ ìºì‹œ í™•ì¸
docker exec local_redis redis-cli hlen cache:users
docker exec local_redis redis-cli hlen cache:products

# ìƒ˜í”Œ ë°ì´í„° ì¡°íšŒ
docker exec local_redis redis-cli hrandfield cache:users 1 withvalues
```

## Python ëŒ€í™”í˜• ì‰˜ (REPL)

### Python ì‰˜ ì‹¤í–‰

```bash
# ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ
python

# ë˜ëŠ” ì™¸ë¶€ì—ì„œ
docker-compose exec python-dev python
```

### ì˜ˆì œ ì‚¬ìš©ë²•

```python
# PostgreSQL í…ŒìŠ¤íŠ¸
>>> from database.database import SessionLocal
>>> from database import crud
>>> db = SessionLocal()
>>> users = crud.get_users(db, limit=5)
>>> for user in users:
...     print(user.name, user.email)
>>> db.close()

# Redis ìºì‹œ í…ŒìŠ¤íŠ¸
>>> from cache.client import get_redis_client
>>> redis_client = get_redis_client()
>>> user = redis_client.get_random_user()
>>> print(f"ëœë¤ ìœ ì €: {user['name']}, {user['region']}")
>>> product = redis_client.get_random_product()
>>> print(f"ëœë¤ ìƒí’ˆ: {product['name']}, {product['price']}ì›")

# Kafka Producer í…ŒìŠ¤íŠ¸
>>> from kafka.producer import KafkaProducer
>>> from datetime import datetime
>>> producer = KafkaProducer()
>>> test_data = {
...     'user_id': 'test_001',
...     'name': 'í…ŒìŠ¤íŠ¸',
...     'email': 'test@example.com',
...     'created_at': datetime.now()
... }
>>> producer.send_event('users', 'test_001', test_data, 'user_created')
>>> producer.close()

# ë°ì´í„° ìƒì„±ê¸° í…ŒìŠ¤íŠ¸
>>> from collect.user_generator import UserGenerator
>>> gen = UserGenerator()
>>> users = gen.generate_batch(10)
>>> print(f'{len(users)}ëª… ìƒì„±ë¨')
>>> print(users[0])
```

### IPython ì‚¬ìš© (ë” ë‚˜ì€ REPL)

```bash
# IPython ì„¤ì¹˜ (í•„ìš”ì‹œ)
docker-compose exec python-dev pip install ipython

# IPython ì‹¤í–‰
docker-compose exec python-dev ipython
```

## ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰

### ê¸°ì¡´ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰

```bash
# í™˜ê²½ í…ŒìŠ¤íŠ¸
docker-compose exec python-dev python tests/test_environment.py

# ë°ì´í„° ìƒì„±ê¸° í…ŒìŠ¤íŠ¸
docker-compose exec python-dev python collect/user_generator.py

# í† í”½ ìƒì„±
docker-compose exec python-dev python kafka/admin/setup_topics.py

# ì´ˆê¸° ë°ì´í„° ìƒì„±
docker-compose exec python-dev python apps/seeders/initial_seeder.py

# Redis ìºì‹œ ì›Œì»¤ í…ŒìŠ¤íŠ¸ (í•œ ë²ˆë§Œ ì‹¤í–‰)
docker-compose exec python-dev python cache/cache_worker.py --once
```

### ì»¤ìŠ¤í…€ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰

```bash
# 1. ë¡œì»¬ì—ì„œ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
# test_script.py

# 2. ì»¨í…Œì´ë„ˆì—ì„œ ì‹¤í–‰ (ë³¼ë¥¨ ë§ˆìš´íŠ¸ë˜ì–´ ìˆìŒ)
docker-compose exec python-dev python test_script.py
```

## ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—…

### SQL ì¿¼ë¦¬ ì‹¤í–‰

```bash
# Pythonìœ¼ë¡œ SQL ì‹¤í–‰
docker-compose exec python-dev python -c "
from database.database import engine
from sqlalchemy import text

with engine.connect() as conn:
    # ìœ ì € ìˆ˜ í™•ì¸
    result = conn.execute(text('SELECT COUNT(*) FROM users'))
    print(f'ìœ ì € ìˆ˜: {result.fetchone()[0]:,}')

    # ìƒí’ˆ ìˆ˜ í™•ì¸
    result = conn.execute(text('SELECT COUNT(*) FROM products'))
    print(f'ìƒí’ˆ ìˆ˜: {result.fetchone()[0]:,}')

    # ì£¼ë¬¸ ìˆ˜ í™•ì¸
    result = conn.execute(text('SELECT COUNT(*) FROM orders'))
    print(f'ì£¼ë¬¸ ìˆ˜: {result.fetchone()[0]:,}')

    # ìºì‹œë˜ì§€ ì•Šì€ ìœ ì € ìˆ˜ í™•ì¸
    result = conn.execute(text('SELECT COUNT(*) FROM users WHERE last_cached_at IS NULL'))
    print(f'ìºì‹œ ì•ˆëœ ìœ ì €: {result.fetchone()[0]:,}')
"
```

### í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ í™•ì¸

```bash
docker-compose exec python-dev python -c "
from database.database import engine, Base
from database import models

# í…Œì´ë¸” ìƒì„± (ì—†ìœ¼ë©´)
Base.metadata.create_all(bind=engine)

# ìŠ¤í‚¤ë§ˆ ì •ë³´
from sqlalchemy import inspect
inspector = inspect(engine)

for table_name in inspector.get_table_names():
    print(f'\ní…Œì´ë¸”: {table_name}')
    for column in inspector.get_columns(table_name):
        print(f'  {column[\"name\"]}: {column[\"type\"]}')
"
```

## Kafka ì‘ì—…

### í† í”½ ëª©ë¡ í™•ì¸

```bash
docker-compose exec python-dev python -c "
from confluent_kafka.admin import AdminClient
from kafka.config import KAFKA_BOOTSTRAP_SERVERS

admin = AdminClient({'bootstrap.servers': KAFKA_BOOTSTRAP_SERVERS})
metadata = admin.list_topics(timeout=10)

print('í† í”½ ëª©ë¡:')
for topic_name, topic_metadata in metadata.topics.items():
    if not topic_name.startswith('_'):
        print(f'  - {topic_name}: {len(topic_metadata.partitions)}ê°œ íŒŒí‹°ì…˜')
"
```

### ë©”ì‹œì§€ ë°œí–‰ í…ŒìŠ¤íŠ¸

```bash
docker-compose exec python-dev python -c "
from kafka.producer import KafkaProducer
from datetime import datetime

producer = KafkaProducer()

# í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ë°œí–‰
test_message = {
    'user_id': 'dev_test_001',
    'name': 'ê°œë°œ í…ŒìŠ¤íŠ¸',
    'email': 'dev@test.com',
    'created_at': datetime.now()
}

success = producer.send_event(
    topic='users',
    key='dev_test_001',
    data=test_message,
    event_type='user_created'
)

print(f'ë©”ì‹œì§€ ë°œí–‰: {\"ì„±ê³µ\" if success else \"ì‹¤íŒ¨\"}')
producer.flush()
producer.close()
"
```

## Redis ì‘ì—…

### ìºì‹œ ìƒíƒœ í™•ì¸

```bash
docker-compose exec python-dev python -c "
from cache.client import get_redis_client

client = get_redis_client()
if client.is_connected():
    print('Redis ì—°ê²° ì„±ê³µ!')

    # ìºì‹œëœ ìœ ì € ìˆ˜
    import redis
    r = redis.Redis(host='redis', port=6379, decode_responses=True)
    users_count = r.hlen('cache:users')
    products_count = r.hlen('cache:products')

    print(f'ìºì‹œëœ ìœ ì €: {users_count}')
    print(f'ìºì‹œëœ ìƒí’ˆ: {products_count}')
"
```

### ëœë¤ ë°ì´í„° ì¡°íšŒ í…ŒìŠ¤íŠ¸

```bash
docker-compose exec python-dev python -c "
from cache.client import get_redis_client

client = get_redis_client()

# 5ëª…ì˜ ëœë¤ ìœ ì € ì¡°íšŒ
for i in range(5):
    user = client.get_random_user()
    if user:
        print(f'{i+1}. {user[\"name\"]} ({user[\"region\"]})')
    else:
        print(f'{i+1}. ìºì‹œì— ë°ì´í„° ì—†ìŒ')
"
```

## ë””ë²„ê¹…

### ë¡œê·¸ ë ˆë²¨ ì¡°ì •

```python
# Python ìŠ¤í¬ë¦½íŠ¸ì—ì„œ
import logging
logging.basicConfig(level=logging.DEBUG)
```

### pdb ë””ë²„ê±° ì‚¬ìš©

```python
# ìŠ¤í¬ë¦½íŠ¸ì— ì¶”ê°€
import pdb; pdb.set_trace()

# ë˜ëŠ”
breakpoint()  # Python 3.7+
```

```bash
# ë””ë²„ê±°ì™€ í•¨ê»˜ ì‹¤í–‰
docker-compose exec python-dev python -m pdb your_script.py
```

## ê°œë°œ ì›Œí¬í”Œë¡œìš°

### 1. ì½”ë“œ ìˆ˜ì •
```bash
# ë¡œì»¬ì—ì„œ ì½”ë“œ ìˆ˜ì •
# ì˜ˆ: collect/user_generator.py
```

### 2. ì¦‰ì‹œ í…ŒìŠ¤íŠ¸
```bash
# ë³€ê²½ì‚¬í•­ì´ ìë™ìœ¼ë¡œ ë°˜ì˜ë¨ (ë³¼ë¥¨ ë§ˆìš´íŠ¸)
docker-compose exec python-dev python collect/user_generator.py
```

### 3. í™˜ê²½ ê²€ì¦
```bash
# ì „ì²´ í™˜ê²½ í…ŒìŠ¤íŠ¸
docker-compose exec python-dev python tests/test_environment.py
```

## íŒ¨í‚¤ì§€ ì„¤ì¹˜

### ì„ì‹œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘ ì‹œ ì‚­ì œë¨)
```bash
docker-compose exec python-dev pip install ipython pandas matplotlib
```

### ì˜êµ¬ íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
# 1. requirements.txtì— ì¶”ê°€
echo "ipython" >> requirements.txt

# 2. ì´ë¯¸ì§€ ì¬ë¹Œë“œ
docker-compose build python-dev

# 3. ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘
docker-compose up -d python-dev
```

## ìœ ìš©í•œ ëª…ë ¹ì–´ ëª¨ìŒ

### ë¹ ë¥¸ í…ŒìŠ¤íŠ¸

```bash
# í™˜ê²½ ì „ì²´ í…ŒìŠ¤íŠ¸
docker-compose exec python-dev python tests/test_environment.py

# DB ì—°ê²°ë§Œ í…ŒìŠ¤íŠ¸
docker-compose exec python-dev python -c "from database.database import engine; print(engine.connect())"

# Kafka ì—°ê²°ë§Œ í…ŒìŠ¤íŠ¸
docker-compose exec python-dev python kafka/test_connection.py

# Redis ì—°ê²°ë§Œ í…ŒìŠ¤íŠ¸
docker-compose exec python-dev python -c "
from cache.client import get_redis_client
print(f'Redis ì—°ê²°: {get_redis_client().is_connected()}')
"

# ë°ì´í„° ìƒì„±ê¸° í…ŒìŠ¤íŠ¸
docker-compose exec python-dev python -c "
from collect.user_generator import UserGenerator
users = UserGenerator().generate_batch(5)
print(f'{len(users)}ëª… ìƒì„±')
"
```

### ë°ì´í„° í™•ì¸

```bash
# ìœ ì € ìˆ˜
docker-compose exec python-dev python -c "
from database.database import SessionLocal
from database import crud
db = SessionLocal()
users = crud.get_users(db, limit=0)
print(f'ì´ ìœ ì € ìˆ˜: {len(users)}')
db.close()
"

# ìµœê·¼ ì£¼ë¬¸ 5ê±´
docker-compose exec python-dev python -c "
from database.database import SessionLocal
from database import models
from sqlalchemy import desc
db = SessionLocal()
orders = db.query(models.Order).order_by(desc(models.Order.created_at)).limit(5).all()
for order in orders:
    print(f'{order.order_id}: {order.total_amount:,}ì›')
db.close()
"

# Redis ìºì‹œ ìƒíƒœ
docker-compose exec python-dev python -c "
import redis
r = redis.Redis(host='redis', port=6379, decode_responses=True)
print(f'ìºì‹œëœ ìœ ì €: {r.hlen(\"cache:users\")}')
print(f'ìºì‹œëœ ìƒí’ˆ: {r.hlen(\"cache:products\")}')
"
```

## Jupyter Notebook (ì„ íƒì‚¬í•­)

### Jupyter ì„¤ì¹˜ ë° ì‹¤í–‰

```bash
# 1. Jupyter ì„¤ì¹˜
docker-compose exec python-dev pip install jupyter

# 2. Jupyter ì‹¤í–‰
docker-compose exec python-dev jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser --allow-root

# 3. docker-compose.ymlì— í¬íŠ¸ ì¶”ê°€ í•„ìš”
# ports:
#   - "8888:8888"
```

## ë¬¸ì œ í•´ê²°

### ì»¨í…Œì´ë„ˆê°€ ì‹œì‘ë˜ì§€ ì•Šì„ ë•Œ
```bash
# ë¡œê·¸ í™•ì¸
docker-compose logs python-dev

# ì»¨í…Œì´ë„ˆ ì¬ìƒì„±
docker-compose up -d --force-recreate python-dev
```

### ì½”ë“œ ë³€ê²½ì´ ë°˜ì˜ë˜ì§€ ì•Šì„ ë•Œ
```bash
# ë³¼ë¥¨ ë§ˆìš´íŠ¸ í™•ì¸
docker-compose exec python-dev ls -la /app

# Python ëª¨ë“ˆ ìºì‹œ ì‚­ì œ
docker-compose exec python-dev find . -type d -name __pycache__ -exec rm -rf {} +
docker-compose exec python-dev find . -type f -name "*.pyc" -delete
```

### íŒ¨í‚¤ì§€ ì¶©ëŒ ì‹œ
```bash
# ì´ë¯¸ì§€ ì¬ë¹Œë“œ (ìºì‹œ ì—†ì´)
docker-compose build --no-cache python-dev

# ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘
docker-compose up -d python-dev
```

### Redis ì—°ê²° ì‹¤íŒ¨ ì‹œ
```bash
# Redis ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
docker-compose ps redis

# Redis ì¬ì‹œì‘
docker-compose restart redis

# ì—°ê²° í…ŒìŠ¤íŠ¸
docker exec local_redis redis-cli ping
```

## ì •ë¦¬

### ì»¨í…Œì´ë„ˆ ì¢…ë£Œ
```bash
docker-compose stop python-dev
```

### ì»¨í…Œì´ë„ˆ ì‚­ì œ
```bash
docker-compose down python-dev
```

### í”„ë¡œíŒŒì¼ë¡œ ê´€ë¦¬
```bash
# dev í”„ë¡œíŒŒì¼ ì„œë¹„ìŠ¤ë§Œ ì‹œì‘
docker-compose --profile dev up -d

# dev í”„ë¡œíŒŒì¼ ì„œë¹„ìŠ¤ë§Œ ì¢…ë£Œ
docker-compose --profile dev down
```

## ìš”ì•½

`python-dev` ì»¨í…Œì´ë„ˆëŠ”:
- ğŸ Python ê°œë°œ í™˜ê²½ ì œê³µ
- ğŸ” í™˜ê²½ í…ŒìŠ¤íŠ¸ ìë™í™”
- ğŸ’» ëŒ€í™”í˜• ì‰˜ (REPL)
- ğŸ”§ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ë° ë””ë²„ê¹…
- ğŸ“ ì½”ë“œ ë³€ê²½ ì‹¤ì‹œê°„ ë°˜ì˜
- âœ… PostgreSQL, Kafka, **Redis** ì—°ê²° ê²€ì¦
- ğŸš€ **Redis ìºì‹œ í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸**

**ê°œë°œ, í…ŒìŠ¤íŠ¸, ë””ë²„ê¹…ì„ ìœ„í•œ ì™„ë²½í•œ í™˜ê²½!**

## ì°¸ê³  ìë£Œ

- **[KAFKA_PRODUCER_GUIDE.md](KAFKA_PRODUCER_GUIDE.md)** - Producer ê°€ì´ë“œ (Redis ìºì‹œ ëª¨ë“œ)
- **[KAFKA_CONSUMER_GUIDE.md](KAFKA_CONSUMER_GUIDE.md)** - Consumer ê°€ì´ë“œ
- **[DB_README.md](DB_README.md)** - DB êµ¬ì¡° ë° ORM ê°€ì´ë“œ
- **[DOCKER_DEPLOYMENT_GUIDE.md](DOCKER_DEPLOYMENT_GUIDE.md)** - Docker ë°°í¬
