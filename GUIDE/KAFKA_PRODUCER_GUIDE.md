# Kafka Producer ê°€ì´ë“œ

## ê°œìš”

Kafka ProducerëŠ” **Redis ìºì‹œì—ì„œ ë°ì´í„°ë¥¼ ì¡°íšŒ**í•˜ì—¬ ì£¼ë¬¸ ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³ , Kafka í† í”½ìœ¼ë¡œ ì´ë²¤íŠ¸ë¥¼ ë°œí–‰í•©ë‹ˆë‹¤. (DB ì €ì¥ì€ Consumerê°€ ë‹´ë‹¹)

### ì•„í‚¤í…ì²˜ (Redis ìºì‹± + Aging)
```
[PostgreSQL] â†’ [Cache-Worker] â†’ [Redis] â†’ [Producer] â†’ [Kafka] â†’ [Consumer] â†’ [DB]
                 (50ì´ˆë§ˆë‹¤)     (1000ê±´)   (ëœë¤ì¡°íšŒ)
```

### ì„±ëŠ¥ í–¥ìƒ
| ì§€í‘œ | Before (DB ì§ì ‘) | After (Redis ìºì‹œ) |
|------|------------------|-------------------|
| DB ì¿¼ë¦¬/ë¶„ | ~60íšŒ | ~1.2íšŒ |
| ì¡°íšŒ ì†ë„ | 10-100ms | 0.1-1ms |

## Producer êµ¬ì„±

### 1. ì´ˆê¸° ë°ì´í„° ìƒì„±
**apps/seeders/initial_seeder.py**
- ê³ ê° 10,000ëª… ìƒì„±
- ìƒí’ˆ 20,000ê°œ ìƒì„±
- ì¼íšŒì„± ì‹¤í–‰

### 2. ì‹¤ì‹œê°„ ë°ì´í„° ìƒì„± (Redis ìºì‹œ ëª¨ë“œ)
**apps/seeders/realtime_generator.py**
- **Redis ìºì‹œì—ì„œ ìœ ì €/ìƒí’ˆ ëœë¤ ì¡°íšŒ**
- ì£¼ë¬¸: 2~8ì´ˆ ê°„ê²©ìœ¼ë¡œ 1~5ê±´ì”© ìƒì„±
- ìƒí’ˆ: 10~20ì´ˆ ê°„ê²©ìœ¼ë¡œ 100ê±´ì”© ìƒì„±
- Kafkaì—ë§Œ ë°œí–‰ (DB ì €ì¥ X)
- ë¬´í•œ ë£¨í”„ (Ctrl+Cë¡œ ì¤‘ì§€)

### 3. Cache Worker (Aging ê¸°ë²•)
**cache/cache_worker.py**
- 50ì´ˆë§ˆë‹¤ DBì—ì„œ 1,000ê±´ì”© Redisë¡œ ìºì‹±
- Aging: 50% ì‹ ê·œ + 50% ê¸°ì¡´ ë°ì´í„° (ê¸°ì•„ ë°©ì§€)
- `last_cached_at` ì»¬ëŸ¼ìœ¼ë¡œ ì¡°íšŒ ì´ë ¥ ê´€ë¦¬

### 4. ë°ì´í„° ìƒì„±ê¸°
- **collect/user_generator.py** - ìœ ì € ë°ì´í„° ìƒì„±
- **collect/product_generator.py** - ìƒí’ˆ ë°ì´í„° ìƒì„±
- **collect/order_generator.py** - ì£¼ë¬¸ ë°ì´í„° ìƒì„±

## ì‹¤í–‰ ë°©ë²•

### Docker ì‹¤í–‰ (ê¶Œì¥)

#### 1. ì „ì²´ ì‹œìŠ¤í…œ ì‹œì‘
```bash
cd deploy
docker-compose build
docker-compose up -d
```

#### 2. Redis ìºì‹œ ëª¨ë‹ˆí„°ë§
```bash
# ì‹¤ì‹œê°„ ìºì‹œ ìƒíƒœ í™•ì¸
docker logs -f redis_monitor

# ì¶œë ¥ ì˜ˆì‹œ:
# [11:45:35] [15/50s ######--------------] | MEM: 2.25M | HIT: 100.0% | CACHE: users=1000, products=1000 | êµì²´: 1íšŒ
```

#### 3. Producer ë¡œê·¸ í™•ì¸
```bash
docker logs -f realtime_producer

# ì¶œë ¥ ì˜ˆì‹œ:
# [14:30:05] ğŸ›’ ì£¼ë¬¸ ë°œí–‰: 3/3ê±´ ì„±ê³µ | ëˆ„ì : 42ê±´ | TPS: 0.70
# [14:30:08] ğŸ“¦ ìƒí’ˆ ë°œí–‰: 100/100ê±´ ì„±ê³µ | ëˆ„ì : 500ê°œ | TPS: 8.33
```

### ë¡œì»¬ ì‹¤í–‰

#### 1. ì´ˆê¸° ë°ì´í„° ìƒì„±
```bash
python apps/seeders/initial_seeder.py
```

#### 2. Redis ìºì‹œ ì›Œì»¤ ì‹œì‘
```bash
python cache/cache_worker.py
```

#### 3. ì‹¤ì‹œê°„ ë°ì´í„° ìƒì„±
```bash
python apps/seeders/realtime_generator.py
```

## ë°ì´í„° ìƒì„± í”Œë¡œìš°

### ì‹¤ì‹œê°„ ì£¼ë¬¸ ìƒì„± (Redis ìºì‹œ ëª¨ë“œ)

```
1. Cache-Worker (50ì´ˆë§ˆë‹¤)
   â””â”€ DBì—ì„œ Aging ê¸°ë²•ìœ¼ë¡œ ì¡°íšŒ
      â”œâ”€ ì‹ ê·œ 500ê±´ (last_cached_at IS NULL)
      â””â”€ ê¸°ì¡´ 500ê±´ (ORDER BY last_cached_at ASC)
   â””â”€ Redis Hashì— ì €ì¥ (cache:users, cache:products)

2. Producer (2~8ì´ˆë§ˆë‹¤)
   â””â”€ Redisì—ì„œ ëœë¤ ì¡°íšŒ (HRANDFIELD)
   â””â”€ ì£¼ë¬¸ ë°ì´í„° ìƒì„±
   â””â”€ Kafka 'orders' í† í”½ì— ë°œí–‰ (DB ì €ì¥ X)

3. Consumer
   â””â”€ Kafkaì—ì„œ ì†Œë¹„
   â””â”€ PostgreSQLì— ì €ì¥
```

### ìƒí’ˆ ìƒì„±

```
ProductGenerator.generate_batch(100)
  â†“
  ìƒì„±ëœ ë°ì´í„° (dict)
  â†“
  Kafka 'products' í† í”½ì— ë°œí–‰
  â†“
  Consumerê°€ DBì— ì €ì¥
```

## Producer ì„¤ì •

### Redis ìºì‹œ ì„¤ì • (docker-compose.yml)

```yaml
# cache-worker í™˜ê²½ë³€ìˆ˜
environment:
  REDIS_HOST: redis
  REDIS_PORT: 6379
  CACHE_REFRESH_INTERVAL: 50     # ìºì‹œ ê°±ì‹  ì£¼ê¸° (ì´ˆ)
  CACHE_BATCH_SIZE: 1000         # ìºì‹œ ë°°ì¹˜ í¬ê¸°
  CACHE_NEW_DATA_RATIO: 0.5      # ì‹ ê·œ ë°ì´í„° ë¹„ìœ¨ (50%)
```

### Kafka ì„¤ì • (kafka/config.py)

```python
KAFKA_CONFIG = {
    'bootstrap.servers': 'localhost:9092,localhost:9093,localhost:9094',
    'client.id': 'sesac-producer',
    'acks': 'all',
    'enable.idempotence': True,
    'linger.ms': 10,
    'compression.type': 'gzip',
    'batch.size': 16384,
}
```

### í™˜ê²½ë³€ìˆ˜

```bash
# Kafka ì„¤ì •
KAFKA_ENABLED=true
KAFKA_BOOTSTRAP_SERVERS=kafka1:29092,kafka2:29093,kafka3:29094

# Redis ì„¤ì •
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_ENABLED=true

# DB ì„¤ì •
DB_TYPE=local
POSTGRES_HOST=postgres
```

## Redis ìºì‹œ í´ë¼ì´ì–¸íŠ¸

### ì‚¬ìš©ë²• (cache/client.py)

```python
from cache.client import get_redis_client

# í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸° (ì‹±ê¸€í†¤)
redis_client = get_redis_client()

# ëœë¤ ìœ ì € ì¡°íšŒ
user = redis_client.get_random_user()
print(user)  # {'user_id': 'u_123', 'name': 'í™ê¸¸ë™', ...}

# ëœë¤ ìƒí’ˆ ì¡°íšŒ
product = redis_client.get_random_product()
print(product)  # {'product_id': 'p_456', 'name': 'ë¬´ì„  ì´ì–´í°', ...}

# ì—°ê²° ìƒíƒœ í™•ì¸
if redis_client.is_connected():
    print("Redis ì—°ê²°ë¨")
```

### ìºì‹œ ë°ì´í„° êµ¬ì¡°

```bash
# Redis Hash êµ¬ì¡°
cache:users     # {user_id: JSON ë°ì´í„°}
cache:products  # {product_id: JSON ë°ì´í„°}

# ë°ì´í„° í™•ì¸
docker exec local_redis redis-cli hlen cache:users      # 1000
docker exec local_redis redis-cli hlen cache:products   # 1000

# ìƒ˜í”Œ ë°ì´í„° ì¡°íšŒ
docker exec local_redis redis-cli hrandfield cache:users 1 withvalues
```

## ë©”ì‹œì§€ í¬ë§·

### Orders í† í”½ (Producer ë°œí–‰)
```json
{
  "event_type": "order_created",
  "data": {
    "order_id": "550e8400-e29b-41d4-a716-446655440000",
    "created_at": "2026-02-03T14:30:00",
    "user_id": "u_12345",
    "product_id": "p_67890",
    "quantity": 2,
    "total_amount": 521500,
    "shipping_cost": 3000,
    "discount_amount": 500,
    "payment_method": "Card",
    "status": "Success",
    "category": "ì „ìì œí’ˆ",
    "user_region": "ì„œìš¸ì‹œ",
    "user_gender": "M",
    "user_age_group": "20ëŒ€"
  }
}
```

### Products í† í”½
```json
{
  "event_type": "product_created",
  "data": {
    "product_id": "p_67890",
    "name": "ë¬´ì„  ì´ì–´í°",
    "category": "ì „ìì œí’ˆ",
    "brand": "Apple",
    "price": 259000,
    "org_price": 299000,
    "discount_rate": 13.37,
    "stock": 150,
    "created_at": "2026-02-03T14:30:00"
  }
}
```

## ëª¨ë‹ˆí„°ë§

### Redis ìºì‹œ ëª¨ë‹ˆí„°ë§
```bash
# Redis Monitor ë¡œê·¸
docker logs -f redis_monitor

# ì¶œë ¥ í˜•ì‹:
# [ì‹œê°„] [ì§„í–‰/50s í”„ë¡œê·¸ë ˆìŠ¤ë°”] | MEM: ë©”ëª¨ë¦¬ | HIT: íˆíŠ¸ìœ¨ | CACHE: users=N, products=N | êµì²´: NíšŒ
```

### Producer ë¡œê·¸
```bash
docker logs -f realtime_producer

# ì¶œë ¥ ì˜ˆì‹œ:
# ğŸš€ ì£¼ë¬¸ ë°ì´í„° ìƒì„± ìŠ¤ë ˆë“œ ì‹œì‘ (Redis ìºì‹œ + Kafka ë°œí–‰ ëª¨ë“œ)...
# [14:30:05] ğŸ›’ ì£¼ë¬¸ ë°œí–‰: 3/3ê±´ ì„±ê³µ | ëˆ„ì : 42ê±´ | TPS: 0.70
```

### Cache Worker ë¡œê·¸
```bash
docker logs -f cache_worker

# ì¶œë ¥ ì˜ˆì‹œ:
# ìºì‹œ ê°±ì‹  #7 ì™„ë£Œ - ìœ ì €: 1000ëª…, ìƒí’ˆ: 1000ê°œ
```

### Kafka UI
```
http://localhost:8080
- Messages íƒ­: ë°œí–‰ëœ ë©”ì‹œì§€ í™•ì¸
- Topics íƒ­: í† í”½ë³„ ë©”ì‹œì§€ ìˆ˜ í™•ì¸
```

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### Redis ìºì‹œì— ë°ì´í„°ê°€ ì—†ì„ ë•Œ
```bash
# 1. Redis ì—°ê²° í™•ì¸
docker exec local_redis redis-cli ping

# 2. ìºì‹œ ë°ì´í„° í™•ì¸
docker exec local_redis redis-cli hlen cache:users
docker exec local_redis redis-cli hlen cache:products

# 3. Cache Worker ë¡œê·¸ í™•ì¸
docker logs cache_worker

# 4. Cache Worker ì¬ì‹œì‘
docker-compose restart cache-worker
```

### Producerê°€ ì£¼ë¬¸ì„ ìƒì„±í•˜ì§€ ì•Šì„ ë•Œ

1. **Redis ì—°ê²° í™•ì¸**
```bash
docker exec realtime_producer python -c "from cache.client import get_redis_client; print(get_redis_client().is_connected())"
```

2. **í™˜ê²½ë³€ìˆ˜ í™•ì¸**
```bash
docker exec realtime_producer env | grep REDIS
```

3. **Producer ì¬ì‹œì‘**
```bash
docker-compose restart producer
```

### Kafka ë°œí–‰ ì‹¤íŒ¨ ì‹œ
```bash
# Kafka ìƒíƒœ í™•ì¸
docker-compose ps kafka1 kafka2 kafka3

# Kafka ì¬ì‹œì‘
docker-compose restart kafka1 kafka2 kafka3

# Producer ì¬ì‹œì‘
docker-compose restart producer
```

## ì„±ëŠ¥ ìµœì í™”

### Cache ì„¤ì • ì¡°ì •
```yaml
# docker-compose.yml
environment:
  CACHE_REFRESH_INTERVAL: 30   # ë” ìì£¼ ê°±ì‹  (30ì´ˆ)
  CACHE_BATCH_SIZE: 2000       # ë” ë§ì´ ìºì‹± (2000ê±´)
  CACHE_NEW_DATA_RATIO: 0.7    # ì‹ ê·œ ë°ì´í„° ë¹„ìœ¨ 70%
```

### Kafka Producer ì„¤ì •
```python
KAFKA_CONFIG = {
    'linger.ms': 5,           # ë” ë¹ ë¥¸ ë°œí–‰
    'batch.size': 32768,      # ë” í° ë°°ì¹˜
    'compression.type': 'lz4', # ë” ë¹ ë¥¸ ì••ì¶•
}
```

## ì°¸ê³  ìë£Œ

- **[KAFKA_SETUP_GUIDE.md](KAFKA_SETUP_GUIDE.md)** - Kafka í´ëŸ¬ìŠ¤í„° ì„¤ì •
- **[KAFKA_CONSUMER_GUIDE.md](KAFKA_CONSUMER_GUIDE.md)** - Consumer ê°€ì´ë“œ
- **[DOCKER_DEPLOYMENT_GUIDE.md](DOCKER_DEPLOYMENT_GUIDE.md)** - Docker ë°°í¬

## ìš”ì•½

### Producer ì—­í•  (Redis ìºì‹œ ëª¨ë“œ)
- âœ… Redis ìºì‹œì—ì„œ ìœ ì €/ìƒí’ˆ ëœë¤ ì¡°íšŒ
- âœ… ì£¼ë¬¸ ë°ì´í„° ìƒì„±
- âœ… Kafka í† í”½ì— ì´ë²¤íŠ¸ ë°œí–‰
- âŒ DB ì§ì ‘ ì €ì¥ (Consumerê°€ ë‹´ë‹¹)

### ë°ì´í„° íë¦„
```
1. Cache-Worker (50ì´ˆë§ˆë‹¤)
   â†’ DBì—ì„œ Aging ê¸°ë²•ìœ¼ë¡œ 1,000ê±´ ì¡°íšŒ
   â†’ Redisì— ìºì‹±

2. Producer (2~8ì´ˆë§ˆë‹¤)
   â†’ Redisì—ì„œ ëœë¤ ì¡°íšŒ
   â†’ ì£¼ë¬¸ ìƒì„± â†’ Kafka ë°œí–‰

3. Consumer
   â†’ Kafkaì—ì„œ ì†Œë¹„
   â†’ PostgreSQLì— ì €ì¥
```

**Redis ìºì‹± + Aging ê¸°ë²•ìœ¼ë¡œ ëŒ€ìš©ëŸ‰ í™˜ê²½ì—ì„œë„ íš¨ìœ¨ì ì¸ ë°ì´í„° ìƒì„±!**
