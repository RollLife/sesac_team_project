version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    container_name: local_postgres
    restart: always
    environment:
      TZ: Asia/Seoul
      PGTZ: Asia/Seoul
      DB_TYPE: local
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-password}
      POSTGRES_DB: ${POSTGRES_DB:-sesac_db}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  # Kafka Broker 1 (Leader)
  kafka1:
    image: confluentinc/cp-kafka:7.6.0
    container_name: kafka1
    restart: always
    environment:
      TZ: Asia/Seoul
      PGTZ: Asia/Seoul
      # KRaft ÏÑ§Ï†ï
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka1:19093,2@kafka2:19093,3@kafka3:19093
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER

      # Î¶¨Ïä§ÎÑà ÏÑ§Ï†ï
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:19093,PLAINTEXT_INTERNAL://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka1:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL

      # ÌÅ¥Îü¨Ïä§ÌÑ∞ ÏÑ§Ï†ï (3Í∞ú Î∏åÎ°úÏª§, Î≥µÏ†ú Ìå©ÌÑ∞ 3)
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false' # ÏàòÎèô ÌÜ†ÌîΩ ÏÉùÏÑ±
      KAFKA_MIN_INSYNC_REPLICAS: 2

      # KRaft Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ ÎîîÎ†âÌÜ†Î¶¨
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
    ports:
      - "9092:9092"
    volumes:
      - kafka1_data:/var/lib/kafka/data
    command: >
      bash -c " if [ ! -f /var/lib/kafka/data/meta.properties ]; then
        kafka-storage format -t MkU3OEVBNTcwNTJENDM2Qk -c /etc/kafka/kafka.properties;
      fi; /etc/confluent/docker/run "

  # Kafka Broker 2 (Replica)
  kafka2:
    image: confluentinc/cp-kafka:7.6.0
    container_name: kafka2
    restart: always
    environment:
      TZ: Asia/Seoul
      PGTZ: Asia/Seoul
      # KRaft ÏÑ§Ï†ï
      KAFKA_NODE_ID: 2
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka1:19093,2@kafka2:19093,3@kafka3:19093
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER

      # Î¶¨Ïä§ÎÑà ÏÑ§Ï†ï
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9093,CONTROLLER://0.0.0.0:19093,PLAINTEXT_INTERNAL://0.0.0.0:29093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9093,PLAINTEXT_INTERNAL://kafka2:29093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL

      # ÌÅ¥Îü¨Ïä§ÌÑ∞ ÏÑ§Ï†ï
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'
      KAFKA_MIN_INSYNC_REPLICAS: 2

      # KRaft Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ ÎîîÎ†âÌÜ†Î¶¨
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
    ports:
      - "9093:9093"
    volumes:
      - kafka2_data:/var/lib/kafka/data
    command: >
      bash -c " if [ ! -f /var/lib/kafka/data/meta.properties ]; then
        kafka-storage format -t MkU3OEVBNTcwNTJENDM2Qk -c /etc/kafka/kafka.properties;
      fi; /etc/confluent/docker/run "

  # Kafka Broker 3 (Replica)
  kafka3:
    image: confluentinc/cp-kafka:7.6.0
    container_name: kafka3
    restart: always
    environment:
      TZ: Asia/Seoul
      PGTZ: Asia/Seoul
      # KRaft ÏÑ§Ï†ï
      KAFKA_NODE_ID: 3
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka1:19093,2@kafka2:19093,3@kafka3:19093
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER

      # Î¶¨Ïä§ÎÑà ÏÑ§Ï†ï
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9094,CONTROLLER://0.0.0.0:19093,PLAINTEXT_INTERNAL://0.0.0.0:29094
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9094,PLAINTEXT_INTERNAL://kafka3:29094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL

      # ÌÅ¥Îü¨Ïä§ÌÑ∞ ÏÑ§Ï†ï
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'
      KAFKA_MIN_INSYNC_REPLICAS: 2

      # KRaft Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ ÎîîÎ†âÌÜ†Î¶¨
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
    ports:
      - "9094:9094"
    volumes:
      - kafka3_data:/var/lib/kafka/data
    command: >
      bash -c " if [ ! -f /var/lib/kafka/data/meta.properties ]; then
        kafka-storage format -t MkU3OEVBNTcwNTJENDM2Qk -c /etc/kafka/kafka.properties;
      fi; /etc/confluent/docker/run "

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: local_kafka_ui
    restart: always
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    environment:
      TZ: Asia/Seoul
      PGTZ: Asia/Seoul
      KAFKA_CLUSTERS_0_NAME: local-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka1:29092,kafka2:29093,kafka3:29094
    ports:
      - "8080:8080"

  # Grafana ÏãúÍ∞ÅÌôî ÏÑúÎπÑÏä§
  grafana:
    image: grafana/grafana-oss:latest
    container_name: local_grafana
    restart: always
    depends_on:
      - postgres
    ports:
      - "3000:3000"
    environment:
      TZ: Asia/Seoul
      PGTZ: Asia/Seoul
      GF_SECURITY_ADMIN_PASSWORD: admin
      GF_USERS_ALLOW_SIGN_UP: "false"
      GF_INSTALL_PLUGINS: frser-sqlite-datasource
      GF_AUTH_ANONYMOUS_ENABLED: "true"
      GF_AUTH_ANONYMOUS_ORG_ROLE: Admin # Îì§Ïñ¥Ïò§ÏûêÎßàÏûê 'Í¥ÄÎ¶¨Ïûê(Admin)' Í∂åÌïú Ï£ºÍ∏∞
    volumes:
      # 1. (Í∏∞Ï°¥) Í∑∏ÎùºÌååÎÇò Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•ÏÜå (ÏÇ¨Ïö©Ïûê ÎπÑÎ≤à Îì± Ï†ÄÏû•)
      - grafana_data:/var/lib/grafana

      # 2. [Ï∂îÍ∞Ä] ÌîÑÎ°úÎπÑÏ†ÄÎãù ÏÑ§Ï†ï ÌååÏùº Ïó∞Í≤∞ (dashboard.ymlÏù¥ ÏûàÎäî Ìè¥Îçî ÌÜµÏß∏Î°ú)
      - ../grafana/provisioning:/etc/grafana/provisioning

      # 3. [Ï∂îÍ∞Ä] Ïã§Ï†ú ÎåÄÏãúÎ≥¥Îìú JSON ÌååÏùº Ïó∞Í≤∞ (analysis.jsonÏù¥ ÏûàÎäî Ìè¥Îçî)
      - ../grafana/dashboards:/var/lib/grafana/dashboards

  # PostgreSQL Í¥ÄÎ¶¨ ÎèÑÍµ¨
  adminer:
    image: adminer:latest
    container_name: local_adminer
    restart: always
    depends_on:
      - postgres
    ports:
      - "8081:8080"
    environment:
      TZ: Asia/Seoul
      PGTZ: Asia/Seoul
      ADMINER_DEFAULT_SERVER: postgres

  # Redis Ï∫êÏãú ÏÑúÎ≤Ñ (Íµ¨Îß§Ïù¥Î†•/ÎØ∏Íµ¨Îß§ Î∂ÑÎ¶¨ Ï†ÅÏû¨)
  redis:
    image: redis:7-alpine
    container_name: local_redis
    restart: always
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 10s
      timeout: 5s
      retries: 3

  # ============================================
  # Python Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖò ÏÑúÎπÑÏä§
  # ============================================

  # DB ÌÖåÏù¥Î∏î Ï¥àÍ∏∞Ìôî
  db-init:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: db_init
    depends_on:
      - postgres
    environment:
      TZ: Asia/Seoul
      PGTZ: Asia/Seoul
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
    command: >
      bash -c "
        echo '‚è≥ PostgreSQL Ï§ÄÎπÑ ÎåÄÍ∏∞ Ï§ë...';
        sleep 5;
        echo 'üöÄ ÌÖåÏù¥Î∏î ÏÉùÏÑ± ÏãúÏûë...';
        python -c 'from database.init_db import init_db; init_db()';
        echo '‚úÖ ÌÖåÏù¥Î∏î Ï¥àÍ∏∞Ìôî ÏôÑÎ£å';
      "
    restart: "no"

  # Kafka ÌÜ†ÌîΩ Ï¥àÍ∏∞Ìôî (Î∏åÎ°úÏª§ Ï§ÄÎπÑ ÎåÄÍ∏∞ ÌõÑ ÌÜ†ÌîΩ ÏÉùÏÑ±)
  kafka-init:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: kafka_init
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    environment:
      TZ: Asia/Seoul
      PGTZ: Asia/Seoul
      KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_ENABLED: "true"
    command: >
      bash -c "
        echo '‚è≥ Kafka Î∏åÎ°úÏª§ Ï§ÄÎπÑ ÎåÄÍ∏∞ Ï§ë...';
        sleep 15;
        echo 'üöÄ ÌÜ†ÌîΩ ÏÉùÏÑ± ÏãúÏûë...';
        python kafka/admin/setup_topics.py;
        echo '‚úÖ ÌÜ†ÌîΩ Ï¥àÍ∏∞Ìôî ÏôÑÎ£å';
      "
    restart: "no"

  # Ï¥àÍ∏∞ Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ± (one-time job)
  initial-seeder:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: initial_seeder
    depends_on:
      db-init:
        condition: service_completed_successfully
      kafka-init:
        condition: service_completed_successfully
    environment:
      TZ: Asia/Seoul
      PGTZ: Asia/Seoul
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_ENABLED: "true"
    command: python apps/seeders/initial_seeder.py
    restart: "no" # Ìïú Î≤àÎßå Ïã§Ìñâ

  # Redis Ï∫êÏãú ÏõåÏª§ (Íµ¨Îß§Ïù¥Î†•/ÎØ∏Íµ¨Îß§ Î∂ÑÎ¶¨ Ï†ÅÏû¨Î°ú DB ‚Üí Redis Í∞±Ïã†)
  cache-worker:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: cache_worker
    depends_on:
      db-init:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
      initial-seeder:
        condition: service_completed_successfully
    environment:
      TZ: Asia/Seoul
      PGTZ: Asia/Seoul
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_ENABLED: "true"
      CACHE_REFRESH_INTERVAL: 50
      CACHE_BATCH_SIZE: 1000
    command: python cache/cache_worker.py
    restart: always

  # Í≥†Í∞ù Îì±Í∏â Í∞±Ïã† Î∞∞Ïπò ÏõåÏª§ (10Î∂Ñ Ï£ºÍ∏∞)
  grade-updater:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: grade_updater
    depends_on:
      db-init:
        condition: service_completed_successfully
      initial-seeder:
        condition: service_completed_successfully
    environment:
      TZ: Asia/Seoul
      PGTZ: Asia/Seoul
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
    command: python -m apps.batch.grade_updater
    restart: always

  # Redis Ïã§ÏãúÍ∞Ñ Î™®ÎãàÌÑ∞ÎßÅ
  redis-monitor:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: redis_monitor
    depends_on:
      - redis
    environment:
      TZ: Asia/Seoul
      PGTZ: Asia/Seoul
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_MONITOR_INTERVAL: 1
      CACHE_REFRESH_INTERVAL: 50
    command: python cache/redis_monitor.py
    restart: always

  # Ïã§ÏãúÍ∞Ñ Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ± (Producer)
  producer:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: realtime_producer
    depends_on:
      db-init:
        condition: service_completed_successfully
      kafka-init:
        condition: service_completed_successfully
      initial-seeder:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
    environment:
      TZ: Asia/Seoul
      PGTZ: Asia/Seoul
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_ENABLED: "true"
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_ENABLED: "true"
    command: python apps/seeders/realtime_generator.py
    restart: always

  # Ïã§ÏãúÍ∞Ñ Í≥†Í∞ù Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ± (User Seeder)
  user-seeder:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: user_seeder
    depends_on:
      db-init:
        condition: service_completed_successfully
      kafka-init:
        condition: service_completed_successfully
      initial-seeder:
        condition: service_completed_successfully
    environment:
      TZ: Asia/Seoul
      PGTZ: Asia/Seoul
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_ENABLED: "true"
    command: python apps/seeders/realtime_generator_user.py --batch-size 10 --interval 10
    restart: always

  # Consumer - Users Group (3Í∞ú Ïù∏Ïä§ÌÑ¥Ïä§)
  user-consumer-1:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: user_consumer_1
    depends_on:
      db-init:
        condition: service_completed_successfully
      kafka-init:
        condition: service_completed_successfully
    environment:
      TZ: Asia/Seoul
      PGTZ: Asia/Seoul
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_ENABLED: "true"
    command: python kafka/consumers/user_consumer.py --id user_consumer_1
    restart: always

  user-consumer-2:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: user_consumer_2
    depends_on:
      db-init:
        condition: service_completed_successfully
      kafka-init:
        condition: service_completed_successfully
    environment:
      TZ: Asia/Seoul
      PGTZ: Asia/Seoul
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_ENABLED: "true"
    command: python kafka/consumers/user_consumer.py --id user_consumer_2
    restart: always

  user-consumer-3:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: user_consumer_3
    depends_on:
      db-init:
        condition: service_completed_successfully
      kafka-init:
        condition: service_completed_successfully
    environment:
      TZ: Asia/Seoul
      PGTZ: Asia/Seoul
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_ENABLED: "true"
    command: python kafka/consumers/user_consumer.py --id user_consumer_3
    restart: always

  # Consumer - Products Group (3Í∞ú Ïù∏Ïä§ÌÑ¥Ïä§)
  product-consumer-1:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: product_consumer_1
    depends_on:
      db-init:
        condition: service_completed_successfully
      kafka-init:
        condition: service_completed_successfully
    environment:
      TZ: Asia/Seoul
      PGTZ: Asia/Seoul
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_ENABLED: "true"
    command: python kafka/consumers/product_consumer.py --id product_consumer_1
    restart: always

  product-consumer-2:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: product_consumer_2
    depends_on:
      db-init:
        condition: service_completed_successfully
      kafka-init:
        condition: service_completed_successfully
    environment:
      TZ: Asia/Seoul
      PGTZ: Asia/Seoul
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_ENABLED: "true"
    command: python kafka/consumers/product_consumer.py --id product_consumer_2
    restart: always

  product-consumer-3:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: product_consumer_3
    depends_on:
      db-init:
        condition: service_completed_successfully
      kafka-init:
        condition: service_completed_successfully
    environment:
      TZ: Asia/Seoul
      PGTZ: Asia/Seoul
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_ENABLED: "true"
    command: python kafka/consumers/product_consumer.py --id product_consumer_3
    restart: always

  # Consumer - Orders Group (3Í∞ú Ïù∏Ïä§ÌÑ¥Ïä§)
  order-consumer-1:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: order_consumer_1
    depends_on:
      db-init:
        condition: service_completed_successfully
      kafka-init:
        condition: service_completed_successfully
    environment:
      TZ: Asia/Seoul
      PGTZ: Asia/Seoul
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_ENABLED: "true"
    command: python kafka/consumers/order_consumer.py --id order_consumer_1
    restart: always

  order-consumer-2:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: order_consumer_2
    depends_on:
      db-init:
        condition: service_completed_successfully
      kafka-init:
        condition: service_completed_successfully
    environment:
      TZ: Asia/Seoul
      PGTZ: Asia/Seoul
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_ENABLED: "true"
    command: python kafka/consumers/order_consumer.py --id order_consumer_2
    restart: always

  # ============================================  
  # Spark Streaming (Local Mode - Îã®ÏàúÌôîÎêú Íµ¨Ï°∞)
  # ============================================

  # Spark Master - Web UI Ï†úÍ≥µ Î∞è Î™®ÎãàÌÑ∞ÎßÅÏö©
  spark-master:
    image: apache/spark:3.5.0
    container_name: spark_master
    user: root
    depends_on:
      - kafka1
      - postgres
    ports:
      - "8082:8080" # Spark Web UI
      - "7077:7077" # Spark Master port
      - "4040:4040" # Spark Application UI
    volumes:
      - ..:/app
    environment:
      TZ: Asia/Seoul
      PYTHONPATH: /app
      PYTHONUNBUFFERED: "1"
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8080" ]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s

  # Spark Streaming - Local Î™®ÎìúÎ°ú ÏßÅÏ†ë Ïã§Ìñâ (Î≥ÑÎèÑ Worker Î∂àÌïÑÏöî)
  spark-streaming:
    image: apache/spark:3.5.0
    container_name: spark_streaming
    user: root
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      db-init:
        condition: service_completed_successfully
    volumes:
      - ..:/app
    environment:
      TZ: Asia/Seoul
      PYTHONPATH: /app
      PYTHONUNBUFFERED: "1"
    command: [ "bash", "-c", "echo '‚è≥ Kafka Ï§ÄÎπÑ ÎåÄÍ∏∞ (15Ï¥à)...' && sleep 15 && echo 'üöÄ Spark Streaming ÏãúÏûë!' && /opt/spark/bin/spark-submit --master local[*] --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.postgresql:postgresql:42.6.0 --conf spark.driver.extraJavaOptions=-Duser.timezone=Asia/Seoul /app/apps/spark/streaming_analysis.py" ]
    restart: on-failure

  # ============================================
  # Jupyter Notebook (Interactive Debugging)
  # ============================================
  jupyter:
    image: jupyter/pyspark-notebook:latest
    container_name: jupyter_notebook
    user: root # Í∂åÌïú Î¨∏Ï†ú Î∞©ÏßÄ
    environment:
      TZ: Asia/Seoul
      PGTZ: Asia/Seoul
      JUPYTER_ENABLE_LAB: "yes"
      GRANT_SUDO: "yes"
    ports:
      - "8888:8888" # Ïõπ Î∏åÎùºÏö∞Ï†Ä Ï†ëÏÜçÏö© Ìè¨Ìä∏
    volumes:
      - ..:/home/jovyan/work # ÌîÑÎ°úÏ†ùÌä∏ Ìè¥ÎçîÎ•º ÎÖ∏Ìä∏Î∂Å ÏûëÏóÖ Ìè¥ÎçîÎ°ú Ïó∞Í≤∞
    networks:
      - default

  order-consumer-3:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: order_consumer_3
    depends_on:
      db-init:
        condition: service_completed_successfully
      kafka-init:
        condition: service_completed_successfully
    environment:
      TZ: Asia/Seoul
      PGTZ: Asia/Seoul
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_ENABLED: "true"
    command: python kafka/consumers/order_consumer.py --id order_consumer_3
    restart: always

  # ============================================
  # Python Í∞úÎ∞ú/ÌÖåÏä§Ìä∏ Ïª®ÌÖåÏù¥ÎÑà
  # ============================================
  python-dev:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: python_dev
    depends_on:
      db-init:
        condition: service_completed_successfully
      kafka-init:
        condition: service_completed_successfully
    environment:
      TZ: Asia/Seoul
      PGTZ: Asia/Seoul
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_ENABLED: "true"
      KAFKA_TOPIC_USERS: users
      KAFKA_TOPIC_PRODUCTS: products
      KAFKA_TOPIC_ORDERS: orders
    command: tail -f /dev/null # Ïª®ÌÖåÏù¥ÎÑàÎ•º Í≥ÑÏÜç Ïã§Ìñâ ÏÉÅÌÉúÎ°ú Ïú†ÏßÄ
    stdin_open: true # STDIN Ïó¥Í∏∞
    tty: true # TTY Ìï†Îãπ
    volumes:
      - .:/app # ÏΩîÎìú ÎèôÍ∏∞Ìôî (Í∞úÎ∞úÏö©)
    profiles:
      - dev # ÌîÑÎ°úÌååÏùº ÏÑ§Ï†ï (ÏÑ†ÌÉùÏ†Å Ïã§Ìñâ)

volumes:
  postgres_data:
  kafka1_data:
  kafka2_data:
  kafka3_data:
  redis_data:
  grafana_data:
