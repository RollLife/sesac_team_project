version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    container_name: local_postgres
    restart: always
    environment:
      DB_TYPE: local
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-password}
      POSTGRES_DB: ${POSTGRES_DB:-sesac_db}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  # Kafka Broker 1 (Leader)
  kafka1:
    image: confluentinc/cp-kafka:7.6.0
    container_name: kafka1
    restart: always
    environment:
      # KRaft 설정
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka1:9093,2@kafka2:9093,3@kafka3:9093
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER

      # 리스너 설정
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093,PLAINTEXT_INTERNAL://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka1:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL

      # 클러스터 설정 (3개 브로커, 복제 팩터 3)
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'  # 수동 토픽 생성
      KAFKA_MIN_INSYNC_REPLICAS: 2

      # KRaft 메타데이터 디렉토리
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
    ports:
      - "9092:9092"
    volumes:
      - kafka1_data:/var/lib/kafka/data
    command: >
      bash -c "
      if [ ! -f /var/lib/kafka/data/meta.properties ]; then
        kafka-storage format -t MkU3OEVBNTcwNTJENDM2Qk -c /etc/kafka/kafka.properties;
      fi;
      /etc/confluent/docker/run
      "

  # Kafka Broker 2 (Replica)
  kafka2:
    image: confluentinc/cp-kafka:7.6.0
    container_name: kafka2
    restart: always
    environment:
      # KRaft 설정
      KAFKA_NODE_ID: 2
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka1:9093,2@kafka2:9093,3@kafka3:9093
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER

      # 리스너 설정
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093,PLAINTEXT_INTERNAL://0.0.0.0:29093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9093,PLAINTEXT_INTERNAL://kafka2:29093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL

      # 클러스터 설정
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'
      KAFKA_MIN_INSYNC_REPLICAS: 2

      # KRaft 메타데이터 디렉토리
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
    ports:
      - "9093:9093"
    volumes:
      - kafka2_data:/var/lib/kafka/data
    command: >
      bash -c "
      if [ ! -f /var/lib/kafka/data/meta.properties ]; then
        kafka-storage format -t MkU3OEVBNTcwNTJENDM2Qk -c /etc/kafka/kafka.properties;
      fi;
      /etc/confluent/docker/run
      "

  # Kafka Broker 3 (Replica)
  kafka3:
    image: confluentinc/cp-kafka:7.6.0
    container_name: kafka3
    restart: always
    environment:
      # KRaft 설정
      KAFKA_NODE_ID: 3
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka1:9093,2@kafka2:9093,3@kafka3:9093
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER

      # 리스너 설정
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093,PLAINTEXT_INTERNAL://0.0.0.0:29094
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9094,PLAINTEXT_INTERNAL://kafka3:29094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL

      # 클러스터 설정
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'
      KAFKA_MIN_INSYNC_REPLICAS: 2

      # KRaft 메타데이터 디렉토리
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
    ports:
      - "9094:9094"
    volumes:
      - kafka3_data:/var/lib/kafka/data
    command: >
      bash -c "
      if [ ! -f /var/lib/kafka/data/meta.properties ]; then
        kafka-storage format -t MkU3OEVBNTcwNTJENDM2Qk -c /etc/kafka/kafka.properties;
      fi;
      /etc/confluent/docker/run
      "

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: local_kafka_ui
    restart: always
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    environment:
      KAFKA_CLUSTERS_0_NAME: local-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka1:29092,kafka2:29093,kafka3:29094
    ports:
      - "8080:8080"

  # PostgreSQL 관리 도구
  adminer:
    image: adminer:latest
    container_name: local_adminer
    restart: always
    depends_on:
      - postgres
    ports:
      - "8081:8080"
    environment:
      ADMINER_DEFAULT_SERVER: postgres

  # ============================================
  # Python 애플리케이션 서비스
  # ============================================

  # 초기 데이터 생성 (one-time job)
  initial-seeder:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: initial_seeder
    depends_on:
      - postgres
      - kafka1
      - kafka2
      - kafka3
    environment:
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_ENABLED: "true"
    command: python apps/seeders/initial_seeder.py
    restart: "no"  # 한 번만 실행

  # 실시간 데이터 생성 (Producer)
  producer:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: realtime_producer
    depends_on:
      - postgres
      - kafka1
      - kafka2
      - kafka3
      - initial-seeder
    environment:
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_ENABLED: "true"
    command: python apps/seeders/realtime_generator.py
    restart: always

  # Consumer - Users Group (3개 인스턴스)
  user-consumer-1:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: user_consumer_1
    depends_on:
      - postgres
      - kafka1
      - kafka2
      - kafka3
    environment:
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_ENABLED: "true"
    command: python kafka/consumers/user_consumer.py --id user_consumer_1
    restart: always

  user-consumer-2:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: user_consumer_2
    depends_on:
      - postgres
      - kafka1
      - kafka2
      - kafka3
    environment:
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_ENABLED: "true"
    command: python kafka/consumers/user_consumer.py --id user_consumer_2
    restart: always

  user-consumer-3:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: user_consumer_3
    depends_on:
      - postgres
      - kafka1
      - kafka2
      - kafka3
    environment:
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_ENABLED: "true"
    command: python kafka/consumers/user_consumer.py --id user_consumer_3
    restart: always

  # Consumer - Products Group (3개 인스턴스)
  product-consumer-1:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: product_consumer_1
    depends_on:
      - postgres
      - kafka1
      - kafka2
      - kafka3
    environment:
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_ENABLED: "true"
    command: python kafka/consumers/product_consumer.py --id product_consumer_1
    restart: always

  product-consumer-2:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: product_consumer_2
    depends_on:
      - postgres
      - kafka1
      - kafka2
      - kafka3
    environment:
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_ENABLED: "true"
    command: python kafka/consumers/product_consumer.py --id product_consumer_2
    restart: always

  product-consumer-3:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: product_consumer_3
    depends_on:
      - postgres
      - kafka1
      - kafka2
      - kafka3
    environment:
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_ENABLED: "true"
    command: python kafka/consumers/product_consumer.py --id product_consumer_3
    restart: always

  # Consumer - Orders Group (3개 인스턴스)
  order-consumer-1:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: order_consumer_1
    depends_on:
      - postgres
      - kafka1
      - kafka2
      - kafka3
    environment:
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_ENABLED: "true"
    command: python kafka/consumers/order_consumer.py --id order_consumer_1
    restart: always

  order-consumer-2:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: order_consumer_2
    depends_on:
      - postgres
      - kafka1
      - kafka2
      - kafka3
    environment:
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_ENABLED: "true"
    command: python kafka/consumers/order_consumer.py --id order_consumer_2
    restart: always

  order-consumer-3:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: order_consumer_3
    depends_on:
      - postgres
      - kafka1
      - kafka2
      - kafka3
    environment:
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_ENABLED: "true"
    command: python kafka/consumers/order_consumer.py --id order_consumer_3
    restart: always

  # ============================================
  # Python 개발/테스트 컨테이너
  # ============================================
  python-dev:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: python_dev
    depends_on:
      - postgres
      - kafka1
      - kafka2
      - kafka3
    environment:
      DB_TYPE: local
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: sesac_db
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_ENABLED: "true"
      KAFKA_TOPIC_USERS: users
      KAFKA_TOPIC_PRODUCTS: products
      KAFKA_TOPIC_ORDERS: orders
    command: tail -f /dev/null  # 컨테이너를 계속 실행 상태로 유지
    stdin_open: true  # STDIN 열기
    tty: true  # TTY 할당
    volumes:
      - .:/app  # 코드 동기화 (개발용)
    profiles:
      - dev  # 프로파일 설정 (선택적 실행)

volumes:
  postgres_data:
  kafka1_data:
  kafka2_data:
  kafka3_data:
